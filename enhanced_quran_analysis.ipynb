{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Enhanced Quranic Root Words Analysis - Phase 1\n",
    "\n",
    "This notebook enhances the basic morphological analysis with:\n",
    "- **Semantic Metadata Layer**: Meaning categories and themes\n",
    "- **Frequency Analysis**: Statistical patterns and distributions\n",
    "- **Thematic Categorization**: Subject-based root groupings\n",
    "- **Co-occurrence Matrices**: Root relationship networks\n",
    "\n",
    "Building upon the foundation from `quran_corrected.ipynb`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ NetworkX not installed. Network analysis features will be skipped.\n",
      "💡 To install: pip install networkx\n",
      "✅ Using seaborn-v0_8 style\n",
      "📚 Enhanced libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Enhanced imports for advanced analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Optional imports with fallbacks\n",
    "try:\n",
    "    import networkx as nx\n",
    "    HAS_NETWORKX = True\n",
    "    print(\"✅ NetworkX available for network analysis\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ NetworkX not installed. Network analysis features will be skipped.\")\n",
    "    print(\"💡 To install: pip install networkx\")\n",
    "    HAS_NETWORKX = False\n",
    "\n",
    "from itertools import combinations\n",
    "import json\n",
    "from functools import lru_cache\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style with fallback\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "    print(\"✅ Using seaborn-v0_8 style\")\n",
    "except OSError:\n",
    "    try:\n",
    "        plt.style.use('seaborn')\n",
    "        print(\"✅ Using seaborn style (fallback)\")\n",
    "    except:\n",
    "        print(\"⚠️ Using default matplotlib style\")\n",
    "\n",
    "sns.set_palette(\"husl\")\n",
    "print(\"📚 Enhanced libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Load and Prepare Base Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Loading processed Quranic data...\n",
      "✅ Loaded 128,219 entries\n",
      "✅ Loaded TOC with 114 suras\n",
      "\n",
      "📊 Dataset Overview:\n",
      "Total entries: 128,219\n",
      "Entries with roots: 49,968\n",
      "Unique roots: 1,642\n",
      "Meccan suras: 86\n",
      "Medinan suras: 28\n"
     ]
    }
   ],
   "source": [
    "# Load the processed data from previous analysis\n",
    "print(\"📥 Loading processed Quranic data...\")\n",
    "try:\n",
    "    quran = pd.read_csv('quran-morphology-final.csv')\n",
    "    print(f\"✅ Loaded {len(quran):,} entries\")\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Base data file not found. Please run quran_corrected.ipynb first.\")\n",
    "    raise\n",
    "\n",
    "# Load table of contents\n",
    "toc = pd.read_csv('toc.csv')\n",
    "print(f\"✅ Loaded TOC with {len(toc)} suras\")\n",
    "\n",
    "# Display basic info\n",
    "print(f\"\\n📊 Dataset Overview:\")\n",
    "print(f\"Total entries: {len(quran):,}\")\n",
    "print(f\"Entries with roots: {quran.Root.notna().sum():,}\")\n",
    "print(f\"Unique roots: {quran.Root.nunique():,}\")\n",
    "print(f\"Meccan suras: {len(toc[toc.Place == 'Meccan'])}\")\n",
    "print(f\"Medinan suras: {len(toc[toc.Place == 'Medinan'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔤 Text conversion functions ready\n"
     ]
    }
   ],
   "source": [
    "# Set up Buckwalter conversion functions (from previous notebook)\n",
    "abjad = {\n",
    "    \"\\u0627\": 'A', \"\\u0628\": 'b', \"\\u062A\": 't', \"\\u062B\": 'v', \"\\u062C\": 'j',\n",
    "    \"\\u062D\": 'H', \"\\u062E\": 'x', \"\\u062F\": 'd', \"\\u0630\": '*', \"\\u0631\": 'r',\n",
    "    \"\\u0632\": 'z', \"\\u0633\": 's', \"\\u0634\": '$', \"\\u0635\": 'S', \"\\u0636\": 'D',\n",
    "    \"\\u0637\": 'T', \"\\u0638\": 'Z', \"\\u0639\": 'E', \"\\u063A\": 'g', \"\\u0641\": 'f',\n",
    "    \"\\u0642\": 'q', \"\\u0643\": 'k', \"\\u0644\": 'l', \"\\u0645\": 'm', \"\\u0646\": 'n',\n",
    "    \"\\u0647\": 'h', \"\\u0648\": 'w', \"\\u0649\": 'Y', \"\\u064A\": 'y',\n",
    "    ' ': ' ', \"\\u0621\": \"'\", \"\\u0623\": '>', \"\\u0625\": '<', \"\\u0624\": '&',\n",
    "    \"\\u0626\": '}', \"\\u0622\": '|', \"\\u064E\": 'a', \"\\u064F\": 'u', \"\\u0650\": 'i',\n",
    "    \"\\u0651\": '~', \"\\u0652\": 'o', \"\\u064B\": 'F', \"\\u064C\": 'N', \"\\u064D\": 'K',\n",
    "    \"\\u0640\": '_', \"\\u0670\": '`', \"\\u0629\": 'p'\n",
    "}\n",
    "\n",
    "alphabet = {v: k for k, v in abjad.items()}\n",
    "\n",
    "def buck_to_arabic(buc):\n",
    "    \"\"\"Convert Buckwalter to Arabic\"\"\"\n",
    "    try:\n",
    "        return ''.join(alphabet.get(x, x) for x in str(buc))\n",
    "    except:\n",
    "        return str(buc)\n",
    "\n",
    "def arabic_to_buck(ara):\n",
    "    \"\"\"Convert Arabic to Buckwalter\"\"\"\n",
    "    try:\n",
    "        return ''.join(abjad.get(x, x) for x in str(ara))\n",
    "    except:\n",
    "        return str(ara)\n",
    "\n",
    "print(\"🔤 Text conversion functions ready\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Semantic Metadata Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Defined 15 semantic categories\n",
      "Total categorized roots: 133\n",
      "\n",
      "🔍 Sample categorization (Buckwalter → Arabic):\n",
      "  rHm → رحم (divine_attributes)\n",
      "  Elm → علم (divine_attributes)\n",
      "  ktb → كتب (books_revelation)\n",
      "  Slw → صلو (worship_ritual)\n",
      "  smw → سمو (natural_elements)\n"
     ]
    }
   ],
   "source": [
    "# Define semantic categories for root classification (in Buckwalter transliteration)\n",
    "semantic_categories = {\n",
    "    # Divine and Religious\n",
    "    'divine_attributes': ['rHm', 'gfr', 'Elm', 'qdr', 'Hkm', 'Ezz', 'Hmd', 'sbH', 'qds', 'wHd'],\n",
    "    'worship_ritual': ['Slw', 'Swm', 'Hjj', 'zkw', 'sjd', 'rkE', 'dEw', '*kr', 'Ebd'],\n",
    "    'faith_belief': ['>mn', 'kfr', '$rk', 'wHd', '<mn', 'yqn', '$kk', 'Znn', 'Slm'],\n",
    "    \n",
    "    # Human Relations and Society\n",
    "    'family_relations': ['>bw', '>mm', 'zwj', 'wld', '>xw', 'E$r', 'qrb', 'rHm', 'Ahl'],\n",
    "    'social_justice': ['Edl', 'Zlm', 'qsT', 'Hqq', 'nSf', 'fsd', 'SlH', '>mn'],\n",
    "    'commerce_economics': ['byE', '$rw', 'rbw', 'dyn', 'qrD', 'tjr', 'ksb', 'nfq', 'ml'],\n",
    "    \n",
    "    # Knowledge and Communication\n",
    "    'knowledge_wisdom': ['Elm', 'Hkm', 'fhm', 'Eql', 'fkr', 'dbr', '*kr', 'fqh', 'E*r'],\n",
    "    'communication': ['qwl', 'klm', 'nTq', 'Swt', 'ndw', 'b$r', 'n*r', 'blg', 'xbr'],\n",
    "    'books_revelation': ['ktb', 'qr>', 'nzl', 'wHy', '>yt', 'tlw', 'HfZ', 'ktp'],\n",
    "    \n",
    "    # Natural World\n",
    "    'creation_nature': ['xlq', 'br>', 'fTr', 'n$>', 'jEl', 'kwn', 'wjd', 'xrj'],\n",
    "    'time_temporal': ['ywm', 'lyl', 'SbH', 'ms>', 'wqt', 'zmn', 'dhr', 'ESr', 'sEp'],\n",
    "    'natural_elements': ['smw', '>rD', 'm>', 'nwr', 'hw>', '$ms', 'qmr', 'njm', 'jbl'],\n",
    "    \n",
    "    # Actions and States\n",
    "    'movement_direction': ['*hb', 'jy>', 'rjE', 'xrj', 'dxl', 'SEd', 'nzl', 'syr', 'Sbr'],\n",
    "    'emotions_states': ['xwf', '>mn', 'Hzn', 'frH', 'gDb', 'rDw', 'Hbb', 'bgD', 'fzE'],\n",
    "    'moral_conduct': ['Sbr', '$kr', 'tqw', 'brr', 'fjr', 'k*b', 'Sdq', '>mn', 'HSn']\n",
    "}\n",
    "\n",
    "print(f\"📋 Defined {len(semantic_categories)} semantic categories\")\n",
    "print(f\"Total categorized roots: {sum(len(roots) for roots in semantic_categories.values())}\")\n",
    "\n",
    "# Show some examples of the categories\n",
    "print(f\"\\n🔍 Sample categorization (Buckwalter → Arabic):\")\n",
    "sample_roots = ['rHm', 'Elm', 'ktb', 'Slw', 'smw']\n",
    "for root in sample_roots:\n",
    "    if any(root in category_roots for category_roots in semantic_categories.values()):\n",
    "        category = next(cat for cat, roots in semantic_categories.items() if root in roots)\n",
    "        print(f\"  {root} → {buck_to_arabic(root)} ({category})\")\n",
    "    else:\n",
    "        print(f\"  {root} → {buck_to_arabic(root)} (uncategorized)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Testing categorization (Buckwalter → Arabic):\n",
      "  rHm → رحم (divine_attributes)\n",
      "  Elm → علم (divine_attributes)\n",
      "  ktb → كتب (books_revelation)\n",
      "  Slw → صلو (worship_ritual)\n",
      "  smw → سمو (natural_elements)\n",
      "\n",
      "📊 Categorization stats:\n",
      "  Categories defined: 15\n",
      "  Roots categorized: 122\n",
      "\n",
      "✅ Root categorization system ready\n"
     ]
    }
   ],
   "source": [
    "# Create reverse mapping: root -> category (using first category found)\n",
    "root_to_category = {}\n",
    "for category, roots in semantic_categories.items():\n",
    "    for root in roots:\n",
    "        if root not in root_to_category:  # Only assign if not already assigned\n",
    "            root_to_category[root] = category\n",
    "\n",
    "def get_semantic_category(root):\n",
    "    \"\"\"Get semantic category for a root\"\"\"\n",
    "    category = root_to_category.get(root, 'uncategorized')\n",
    "    # Ensure we always return a string, not a list (for pandas compatibility)\n",
    "    if isinstance(category, list):\n",
    "        return category[0]  # Take first category if multiple\n",
    "    return category\n",
    "\n",
    "# Test the function with Buckwalter roots\n",
    "test_roots = ['rHm', 'Elm', 'ktb', 'Slw', 'smw']\n",
    "print(f\"\\n🔍 Testing categorization (Buckwalter → Arabic):\")\n",
    "for root in test_roots:\n",
    "    category = get_semantic_category(root)\n",
    "    print(f\"  {root} → {buck_to_arabic(root)} ({category})\")\n",
    "\n",
    "print(f\"\\n📊 Categorization stats:\")\n",
    "categorized_count = len(root_to_category)\n",
    "total_categories = len(semantic_categories)\n",
    "print(f\"  Categories defined: {total_categories}\")\n",
    "print(f\"  Roots categorized: {categorized_count}\")\n",
    "print(f\"\\n✅ Root categorization system ready\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Frequency Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Calculating frequency analysis...\n",
      "Most frequent root: اله (2851 occurrences)\n",
      "Meccan most frequent: قول (1248 occurrences)\n",
      "Medinan most frequent: اله (1759 occurrences)\n",
      "\n",
      "Sura with most unique roots: 2 (585 unique roots)\n",
      "\n",
      "✅ Frequency analysis complete for 1642 roots\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>root</th>\n",
       "      <th>total_frequency</th>\n",
       "      <th>meccan_frequency</th>\n",
       "      <th>medinan_frequency</th>\n",
       "      <th>meccan_ratio</th>\n",
       "      <th>medinan_ratio</th>\n",
       "      <th>semantic_category</th>\n",
       "      <th>root_arabic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alh</td>\n",
       "      <td>2851</td>\n",
       "      <td>1092</td>\n",
       "      <td>1759</td>\n",
       "      <td>0.383024</td>\n",
       "      <td>0.616976</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>اله</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qwl</td>\n",
       "      <td>1722</td>\n",
       "      <td>1248</td>\n",
       "      <td>474</td>\n",
       "      <td>0.724739</td>\n",
       "      <td>0.275261</td>\n",
       "      <td>communication</td>\n",
       "      <td>قول</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kwn</td>\n",
       "      <td>1390</td>\n",
       "      <td>920</td>\n",
       "      <td>470</td>\n",
       "      <td>0.661871</td>\n",
       "      <td>0.338129</td>\n",
       "      <td>creation_nature</td>\n",
       "      <td>كون</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rbb</td>\n",
       "      <td>980</td>\n",
       "      <td>762</td>\n",
       "      <td>218</td>\n",
       "      <td>0.777551</td>\n",
       "      <td>0.222449</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>ربب</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amn</td>\n",
       "      <td>879</td>\n",
       "      <td>379</td>\n",
       "      <td>500</td>\n",
       "      <td>0.431172</td>\n",
       "      <td>0.568828</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>امن</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Elm</td>\n",
       "      <td>854</td>\n",
       "      <td>495</td>\n",
       "      <td>359</td>\n",
       "      <td>0.579625</td>\n",
       "      <td>0.420375</td>\n",
       "      <td>divine_attributes</td>\n",
       "      <td>علم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>qwm</td>\n",
       "      <td>660</td>\n",
       "      <td>454</td>\n",
       "      <td>206</td>\n",
       "      <td>0.687879</td>\n",
       "      <td>0.312121</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>قوم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Aty</td>\n",
       "      <td>549</td>\n",
       "      <td>339</td>\n",
       "      <td>210</td>\n",
       "      <td>0.617486</td>\n",
       "      <td>0.382514</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>اتي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kfr</td>\n",
       "      <td>525</td>\n",
       "      <td>233</td>\n",
       "      <td>292</td>\n",
       "      <td>0.443810</td>\n",
       "      <td>0.556190</td>\n",
       "      <td>faith_belief</td>\n",
       "      <td>كفر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>byn</td>\n",
       "      <td>523</td>\n",
       "      <td>304</td>\n",
       "      <td>219</td>\n",
       "      <td>0.581262</td>\n",
       "      <td>0.418738</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>بين</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  root  total_frequency  meccan_frequency  medinan_frequency  meccan_ratio  \\\n",
       "0  Alh             2851              1092               1759      0.383024   \n",
       "1  qwl             1722              1248                474      0.724739   \n",
       "2  kwn             1390               920                470      0.661871   \n",
       "3  rbb              980               762                218      0.777551   \n",
       "4  Amn              879               379                500      0.431172   \n",
       "5  Elm              854               495                359      0.579625   \n",
       "6  qwm              660               454                206      0.687879   \n",
       "7  Aty              549               339                210      0.617486   \n",
       "8  kfr              525               233                292      0.443810   \n",
       "9  byn              523               304                219      0.581262   \n",
       "\n",
       "   medinan_ratio  semantic_category root_arabic  \n",
       "0       0.616976      uncategorized         اله  \n",
       "1       0.275261      communication         قول  \n",
       "2       0.338129    creation_nature         كون  \n",
       "3       0.222449      uncategorized         ربب  \n",
       "4       0.568828      uncategorized         امن  \n",
       "5       0.420375  divine_attributes         علم  \n",
       "6       0.312121      uncategorized         قوم  \n",
       "7       0.382514      uncategorized         اتي  \n",
       "8       0.556190       faith_belief         كفر  \n",
       "9       0.418738      uncategorized         بين  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate comprehensive frequency statistics\n",
    "print(\"📊 Calculating frequency analysis...\")\n",
    "\n",
    "# Overall root frequencies\n",
    "root_frequencies = quran[quran.Root.notna()].Root.value_counts()\n",
    "print(f\"Most frequent root: {buck_to_arabic(root_frequencies.index[0])} ({root_frequencies.iloc[0]} occurrences)\")\n",
    "\n",
    "# Frequency by revelation type\n",
    "meccan_freq = quran[(quran.Place == 'Meccan') & (quran.Root.notna())].Root.value_counts()\n",
    "medinan_freq = quran[(quran.Place == 'Medinan') & (quran.Root.notna())].Root.value_counts()\n",
    "\n",
    "print(f\"Meccan most frequent: {buck_to_arabic(meccan_freq.index[0])} ({meccan_freq.iloc[0]} occurrences)\")\n",
    "print(f\"Medinan most frequent: {buck_to_arabic(medinan_freq.index[0])} ({medinan_freq.iloc[0]} occurrences)\")\n",
    "\n",
    "# Frequency by sura\n",
    "sura_root_counts = quran[quran.Root.notna()].groupby('sura').Root.nunique().sort_values(ascending=False)\n",
    "print(f\"\\nSura with most unique roots: {sura_root_counts.index[0]} ({sura_root_counts.iloc[0]} unique roots)\")\n",
    "\n",
    "# Create frequency dataframe\n",
    "frequency_stats = pd.DataFrame({\n",
    "    'root': root_frequencies.index,\n",
    "    'total_frequency': root_frequencies.values,\n",
    "    'meccan_frequency': [meccan_freq.get(root, 0) for root in root_frequencies.index],\n",
    "    'medinan_frequency': [medinan_freq.get(root, 0) for root in root_frequencies.index]\n",
    "})\n",
    "\n",
    "# Add relative frequencies\n",
    "frequency_stats['meccan_ratio'] = frequency_stats['meccan_frequency'] / frequency_stats['total_frequency']\n",
    "frequency_stats['medinan_ratio'] = frequency_stats['medinan_frequency'] / frequency_stats['total_frequency']\n",
    "\n",
    "# Add semantic categories\n",
    "frequency_stats['semantic_category'] = frequency_stats['root'].apply(get_semantic_category)\n",
    "\n",
    "# Add Arabic forms\n",
    "frequency_stats['root_arabic'] = frequency_stats['root'].apply(buck_to_arabic)\n",
    "\n",
    "print(f\"\\n✅ Frequency analysis complete for {len(frequency_stats)} roots\")\n",
    "frequency_stats.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Advanced frequency patterns...\n",
      "\n",
      "🕌 Strongly Meccan-preferred roots (>80%, ≥5 occurrences): 179\n",
      "Top 10:\n",
      "       فطر (   fTr) - 100.0% Meccan (20 total)\n",
      "       كشف (   k$f) - 100.0% Meccan (20 total)\n",
      "       ضحو (   DHw) - 100.0% Meccan (7 total)\n",
      "       فرط (   frT) - 100.0% Meccan (8 total)\n",
      "       سري (   sry) - 100.0% Meccan (8 total)\n",
      "       خسف (   xsf) - 100.0% Meccan (8 total)\n",
      "       مهل (   mhl) - 100.0% Meccan (6 total)\n",
      "       اسف (   Asf) - 100.0% Meccan (5 total)\n",
      "       طرد (   Trd) - 100.0% Meccan (5 total)\n",
      "       صنم (   Snm) - 100.0% Meccan (5 total)\n",
      "\n",
      "🏛️ Strongly Medinan-preferred roots (>80%, ≥5 occurrences): 50\n",
      "Top 10:\n",
      "       لوي (   lwy) - 100.0% Medinan (5 total)\n",
      "       حرف (   Hrf) - 100.0% Medinan (6 total)\n",
      "       شطر (   $Tr) - 100.0% Medinan (5 total)\n",
      "       شحح (   $HH) - 100.0% Medinan (5 total)\n",
      "       اسر (   Asr) - 100.0% Medinan (6 total)\n",
      "       ميل (   myl) - 100.0% Medinan (6 total)\n",
      "       ثقف (   vqf) - 100.0% Medinan (6 total)\n",
      "      زلزل (  zlzl) - 100.0% Medinan (6 total)\n",
      "       صيد (   Syd) - 100.0% Medinan (6 total)\n",
      "       بغض (   bgD) - 100.0% Medinan (5 total)\n",
      "\n",
      "🔹 Rare roots (≤2 occurrences): 592 (36.1% of all roots)\n"
     ]
    }
   ],
   "source": [
    "# Advanced frequency analysis\n",
    "print(\"🔍 Advanced frequency patterns...\")\n",
    "\n",
    "# Roots with strong Meccan preference (>80% Meccan)\n",
    "meccan_preferred = frequency_stats[\n",
    "    (frequency_stats['meccan_ratio'] > 0.8) & \n",
    "    (frequency_stats['total_frequency'] >= 5)  # At least 5 occurrences\n",
    "].sort_values('meccan_ratio', ascending=False)\n",
    "\n",
    "print(f\"\\n🕌 Strongly Meccan-preferred roots (>80%, ≥5 occurrences): {len(meccan_preferred)}\")\n",
    "print(\"Top 10:\")\n",
    "for _, row in meccan_preferred.head(10).iterrows():\n",
    "    print(f\"  {row['root_arabic']:>8} ({row['root']:>6}) - {row['meccan_ratio']:.1%} Meccan ({row['total_frequency']} total)\")\n",
    "\n",
    "# Roots with strong Medinan preference (>80% Medinan)\n",
    "medinan_preferred = frequency_stats[\n",
    "    (frequency_stats['medinan_ratio'] > 0.8) & \n",
    "    (frequency_stats['total_frequency'] >= 5)\n",
    "].sort_values('medinan_ratio', ascending=False)\n",
    "\n",
    "print(f\"\\n🏛️ Strongly Medinan-preferred roots (>80%, ≥5 occurrences): {len(medinan_preferred)}\")\n",
    "print(\"Top 10:\")\n",
    "for _, row in medinan_preferred.head(10).iterrows():\n",
    "    print(f\"  {row['root_arabic']:>8} ({row['root']:>6}) - {row['medinan_ratio']:.1%} Medinan ({row['total_frequency']} total)\")\n",
    "\n",
    "# Rare roots (appear only 1-2 times)\n",
    "rare_roots = frequency_stats[frequency_stats['total_frequency'] <= 2]\n",
    "print(f\"\\n🔹 Rare roots (≤2 occurrences): {len(rare_roots)} ({len(rare_roots)/len(frequency_stats):.1%} of all roots)\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Thematic Categorization Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Thematic categorization analysis...\n",
      "\n",
      "📊 Semantic category statistics:\n",
      "                    root_count  total_occurrences  avg_frequency  \\\n",
      "semantic_category                                                  \n",
      "uncategorized             1541              36140          23.45   \n",
      "creation_nature              6               2306         384.33   \n",
      "communication                9               2252         250.22   \n",
      "divine_attributes           10               2121         212.10   \n",
      "worship_ritual               9               1089         121.00   \n",
      "social_justice               7                892         127.43   \n",
      "faith_belief                 5                805         161.00   \n",
      "books_revelation             5                797         159.40   \n",
      "natural_elements             6                689         114.83   \n",
      "moral_conduct                6                586          97.67   \n",
      "time_temporal                6                562          93.67   \n",
      "family_relations             5                433          86.60   \n",
      "movement_direction           6                425          70.83   \n",
      "emotions_states              8                391          48.88   \n",
      "commerce_economics           7                336          48.00   \n",
      "knowledge_wisdom             6                144          24.00   \n",
      "\n",
      "                    meccan_total  medinan_total  meccan_ratio  \n",
      "semantic_category                                              \n",
      "uncategorized              21514          14626      0.595296  \n",
      "creation_nature             1584            722      0.686904  \n",
      "communication               1628            624      0.722913  \n",
      "divine_attributes           1240            881      0.584630  \n",
      "worship_ritual               743            346      0.682277  \n",
      "social_justice               573            319      0.642377  \n",
      "faith_belief                 435            370      0.540373  \n",
      "books_revelation             456            341      0.572146  \n",
      "natural_elements             463            226      0.671988  \n",
      "moral_conduct                384            202      0.655290  \n",
      "time_temporal                417            145      0.741993  \n",
      "family_relations             236            197      0.545035  \n",
      "movement_direction           272            153      0.640000  \n",
      "emotions_states              191            200      0.488491  \n",
      "commerce_economics           114            222      0.339286  \n",
      "knowledge_wisdom              89             55      0.618056  \n",
      "\n",
      "🎭 Categories with revelation preferences:\n",
      "  🕌 communication: 72.3% Meccan\n",
      "  🕌 time_temporal: 74.2% Meccan\n"
     ]
    }
   ],
   "source": [
    "# Analyze frequency patterns by semantic category\n",
    "print(\"🎯 Thematic categorization analysis...\")\n",
    "\n",
    "# Category frequency distribution\n",
    "category_stats = frequency_stats.groupby('semantic_category').agg({\n",
    "    'total_frequency': ['count', 'sum', 'mean'],\n",
    "    'meccan_frequency': 'sum',\n",
    "    'medinan_frequency': 'sum'\n",
    "}).round(2)\n",
    "\n",
    "category_stats.columns = ['root_count', 'total_occurrences', 'avg_frequency', 'meccan_total', 'medinan_total']\n",
    "category_stats['meccan_ratio'] = category_stats['meccan_total'] / (category_stats['meccan_total'] + category_stats['medinan_total'])\n",
    "category_stats = category_stats.sort_values('total_occurrences', ascending=False)\n",
    "\n",
    "print(\"\\n📊 Semantic category statistics:\")\n",
    "print(category_stats)\n",
    "\n",
    "# Find categories with strong revelation type preferences\n",
    "print(\"\\n🎭 Categories with revelation preferences:\")\n",
    "for category, row in category_stats.iterrows():\n",
    "    if row['meccan_ratio'] > 0.7:\n",
    "        print(f\"  🕌 {category}: {row['meccan_ratio']:.1%} Meccan\")\n",
    "    elif row['meccan_ratio'] < 0.3:\n",
    "        print(f\"  🏛️ {category}: {1-row['meccan_ratio']:.1%} Medinan\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 Thematic distribution by sura...\n",
      "✅ Thematic analysis complete for 114 suras\n",
      "Categories tracked: ['books_revelation', 'commerce_economics', 'communication', 'creation_nature', 'divine_attributes', 'emotions_states', 'faith_belief', 'family_relations', 'knowledge_wisdom', 'moral_conduct', 'movement_direction', 'natural_elements', 'social_justice', 'time_temporal', 'uncategorized', 'worship_ritual']\n",
      "\n",
      "📖 Example - Al-Fatiha (Sura 1) thematic breakdown:\n",
      "  uncategorized: 52.2%\n",
      "  divine_attributes: 26.1%\n",
      "  commerce_economics: 4.3%\n",
      "  emotions_states: 4.3%\n",
      "  natural_elements: 4.3%\n",
      "  time_temporal: 4.3%\n",
      "  worship_ritual: 4.3%\n"
     ]
    }
   ],
   "source": [
    "# Create thematic distribution by sura\n",
    "print(\"📚 Thematic distribution by sura...\")\n",
    "\n",
    "# Add semantic categories to main dataset\n",
    "quran_enhanced = quran.copy()\n",
    "quran_enhanced['semantic_category'] = quran_enhanced['Root'].apply(get_semantic_category)\n",
    "\n",
    "# Calculate category distribution by sura\n",
    "sura_theme_distribution = quran_enhanced[quran_enhanced.Root.notna()].groupby(['sura', 'semantic_category']).size().unstack(fill_value=0)\n",
    "\n",
    "# Calculate relative distributions\n",
    "sura_theme_relative = sura_theme_distribution.div(sura_theme_distribution.sum(axis=1), axis=0)\n",
    "\n",
    "print(f\"✅ Thematic analysis complete for {len(sura_theme_distribution)} suras\")\n",
    "print(f\"Categories tracked: {list(sura_theme_distribution.columns)}\")\n",
    "\n",
    "# Show example for Al-Fatiha\n",
    "print(\"\\n📖 Example - Al-Fatiha (Sura 1) thematic breakdown:\")\n",
    "if 1 in sura_theme_relative.index:\n",
    "    fatiha_themes = sura_theme_relative.loc[1]\n",
    "    for theme, ratio in fatiha_themes[fatiha_themes > 0].sort_values(ascending=False).items():\n",
    "        print(f\"  {theme}: {ratio:.1%}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Co-occurrence Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Calculating root co-occurrence matrices...\n",
      "Analyzed 6214 verses with roots\n",
      "Average roots per verse: 8.0\n",
      "Max roots in a verse: 84\n",
      "\n",
      "🔢 Found 74185 unique root pairs\n",
      "Total co-occurrence instances: 211298\n",
      "\n",
      "🔝 Top 10 most co-occurring root pairs:\n",
      "  اله + قول: 514 times\n",
      "  اله + كون: 441 times\n",
      "  اله + علم: 408 times\n",
      "  اله + امن: 372 times\n",
      "  كون + قول: 369 times\n",
      "  قول + ربب: 329 times\n",
      "  شيا + اله: 282 times\n",
      "  اله + قوم: 242 times\n",
      "  علم + قول: 230 times\n",
      "  اله + كفر: 225 times\n"
     ]
    }
   ],
   "source": [
    "# Calculate root co-occurrences within verses\n",
    "print(\"🔗 Calculating root co-occurrence matrices...\")\n",
    "\n",
    "# Group by verse to find roots that appear together\n",
    "verse_roots = quran_enhanced[quran_enhanced.Root.notna()].groupby(['sura', 'aya'])['Root'].apply(list).reset_index()\n",
    "verse_roots['root_count'] = verse_roots['Root'].apply(len)\n",
    "\n",
    "print(f\"Analyzed {len(verse_roots)} verses with roots\")\n",
    "print(f\"Average roots per verse: {verse_roots['root_count'].mean():.1f}\")\n",
    "print(f\"Max roots in a verse: {verse_roots['root_count'].max()}\")\n",
    "\n",
    "# Calculate co-occurrence matrix\n",
    "cooccurrence_counts = defaultdict(int)\n",
    "total_pairs = 0\n",
    "\n",
    "for _, row in verse_roots.iterrows():\n",
    "    roots_in_verse = list(set(row['Root']))  # Remove duplicates within verse\n",
    "    if len(roots_in_verse) > 1:\n",
    "        for root1, root2 in combinations(roots_in_verse, 2):\n",
    "            # Sort pair to ensure consistent ordering\n",
    "            pair = tuple(sorted([root1, root2]))\n",
    "            cooccurrence_counts[pair] += 1\n",
    "            total_pairs += 1\n",
    "\n",
    "print(f\"\\n🔢 Found {len(cooccurrence_counts)} unique root pairs\")\n",
    "print(f\"Total co-occurrence instances: {total_pairs}\")\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "cooccurrence_df = pd.DataFrame([\n",
    "    {'root1': pair[0], 'root2': pair[1], 'cooccurrence_count': count}\n",
    "    for pair, count in cooccurrence_counts.items()\n",
    "]).sort_values('cooccurrence_count', ascending=False)\n",
    "\n",
    "print(\"\\n🔝 Top 10 most co-occurring root pairs:\")\n",
    "for _, row in cooccurrence_df.head(10).iterrows():\n",
    "    r1_ar = buck_to_arabic(row['root1'])\n",
    "    r2_ar = buck_to_arabic(row['root2'])\n",
    "    print(f\"  {r1_ar} + {r2_ar}: {row['cooccurrence_count']} times\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎭 Semantic category co-occurrence analysis...\n",
      "📊 Categorization results:\n",
      "  Total root pairs: 74185\n",
      "  Pairs with at least one categorized root: 26198\n",
      "  Categorization coverage: 35.3%\n",
      "\n",
      "🎯 Top semantic category co-occurrences:\n",
      "  communication + creation_nature: 746 co-occurrences\n",
      "  creation_nature + divine_attributes: 713 co-occurrences\n",
      "  communication + divine_attributes: 680 co-occurrences\n",
      "  divine_attributes (internal): 494 co-occurrences\n",
      "  creation_nature + worship_ritual: 381 co-occurrences\n",
      "  creation_nature + social_justice: 356 co-occurrences\n",
      "  divine_attributes + worship_ritual: 356 co-occurrences\n",
      "  communication + worship_ritual: 354 co-occurrences\n",
      "  books_revelation + divine_attributes: 338 co-occurrences\n",
      "  creation_nature + natural_elements: 329 co-occurrences\n",
      "  divine_attributes + social_justice: 306 co-occurrences\n",
      "  creation_nature + faith_belief: 304 co-occurrences\n",
      "  communication + social_justice: 300 co-occurrences\n",
      "  communication + faith_belief: 291 co-occurrences\n",
      "  books_revelation + communication: 285 co-occurrences\n"
     ]
    }
   ],
   "source": [
    "# Calculate semantic co-occurrence patterns\n",
    "print(\"🎭 Semantic category co-occurrence analysis...\")\n",
    "\n",
    "# Add semantic categories to co-occurrence data\n",
    "cooccurrence_df['category1'] = cooccurrence_df['root1'].apply(get_semantic_category)\n",
    "cooccurrence_df['category2'] = cooccurrence_df['root2'].apply(get_semantic_category)\n",
    "\n",
    "# Check categorization success\n",
    "categorized_pairs = cooccurrence_df[(cooccurrence_df['category1'] != 'uncategorized') | \n",
    "                                    (cooccurrence_df['category2'] != 'uncategorized')]\n",
    "print(f\"📊 Categorization results:\")\n",
    "print(f\"  Total root pairs: {len(cooccurrence_df)}\")\n",
    "print(f\"  Pairs with at least one categorized root: {len(categorized_pairs)}\")\n",
    "print(f\"  Categorization coverage: {len(categorized_pairs)/len(cooccurrence_df)*100:.1f}%\")\n",
    "\n",
    "# Calculate category-level co-occurrences\n",
    "category_cooccurrence = defaultdict(int)\n",
    "for _, row in cooccurrence_df.iterrows():\n",
    "    cat_pair = tuple(sorted([row['category1'], row['category2']]))\n",
    "    category_cooccurrence[cat_pair] += row['cooccurrence_count']\n",
    "\n",
    "# Create DataFrame with error handling\n",
    "categorized_pairs_data = [\n",
    "    {'category1': pair[0], 'category2': pair[1], 'total_cooccurrence': count}\n",
    "    for pair, count in category_cooccurrence.items()\n",
    "    if pair[0] != 'uncategorized' and pair[1] != 'uncategorized'  # Filter out uncategorized\n",
    "]\n",
    "\n",
    "if categorized_pairs_data:\n",
    "    category_cooccurrence_df = pd.DataFrame(categorized_pairs_data).sort_values('total_cooccurrence', ascending=False)\n",
    "    \n",
    "    print(f\"\\n🎯 Top semantic category co-occurrences:\")\n",
    "    for _, row in category_cooccurrence_df.head(15).iterrows():\n",
    "        if row['category1'] != row['category2']:  # Different categories\n",
    "            print(f\"  {row['category1']} + {row['category2']}: {row['total_cooccurrence']} co-occurrences\")\n",
    "        else:  # Same category (internal consistency)\n",
    "            print(f\"  {row['category1']} (internal): {row['total_cooccurrence']} co-occurrences\")\n",
    "else:\n",
    "    print(\"⚠️  No categorized pairs found for co-occurrence analysis\")\n",
    "    print(\"💡 This suggests the semantic categories need adjustment to match the actual root data\")\n",
    "    # Create empty DataFrame to prevent errors downstream\n",
    "    category_cooccurrence_df = pd.DataFrame(columns=['category1', 'category2', 'total_cooccurrence'])\n",
    "    \n",
    "    # Show some examples of actual roots for debugging\n",
    "    print(f\"\\n🔍 Sample actual roots in data:\")\n",
    "    sample_roots = cooccurrence_df['root1'].head(10).tolist()\n",
    "    for root in sample_roots[:5]:\n",
    "        category = get_semantic_category(root)\n",
    "        print(f\"  {root} → {buck_to_arabic(root)} ({category})\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. Enhanced Dataset Creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💎 Creating enhanced dataset with all metadata...\n",
      "✅ Enhanced dataset created with 128219 entries\n",
      "New columns added: ['semantic_category', 'root_total_freq', 'root_meccan_freq', 'root_medinan_freq', 'root_meccan_ratio', 'root_frequency_rank', 'root_arabic', 'root_rarity', 'revelation_preference']\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive enhanced dataset\n",
    "print(\"💎 Creating enhanced dataset with all metadata...\")\n",
    "\n",
    "# Merge frequency statistics with root data\n",
    "frequency_lookup = frequency_stats.set_index('root').to_dict('index')\n",
    "\n",
    "def add_frequency_info(root):\n",
    "    if pd.isna(root) or root not in frequency_lookup:\n",
    "        return {'total_freq': 0, 'meccan_freq': 0, 'medinan_freq': 0, 'meccan_ratio': 0, 'frequency_rank': 0}\n",
    "    info = frequency_lookup[root]\n",
    "    return {\n",
    "        'total_freq': info['total_frequency'],\n",
    "        'meccan_freq': info['meccan_frequency'], \n",
    "        'medinan_freq': info['medinan_frequency'],\n",
    "        'meccan_ratio': info['meccan_ratio'],\n",
    "        'frequency_rank': frequency_stats[frequency_stats['root'] == root].index[0] + 1\n",
    "    }\n",
    "\n",
    "# Add all enhancements to the dataset\n",
    "enhanced_quran = quran_enhanced.copy()\n",
    "\n",
    "# Add frequency information\n",
    "freq_info = enhanced_quran['Root'].apply(add_frequency_info)\n",
    "for key in ['total_freq', 'meccan_freq', 'medinan_freq', 'meccan_ratio', 'frequency_rank']:\n",
    "    enhanced_quran[f'root_{key}'] = [info[key] for info in freq_info]\n",
    "\n",
    "# Add Arabic root form\n",
    "enhanced_quran['root_arabic'] = enhanced_quran['Root'].apply(lambda x: buck_to_arabic(x) if pd.notna(x) else '')\n",
    "\n",
    "# Add rarity classification\n",
    "def classify_rarity(freq):\n",
    "    if freq == 0: return 'no_root'\n",
    "    elif freq == 1: return 'hapax_legomena'\n",
    "    elif freq <= 5: return 'very_rare'\n",
    "    elif freq <= 20: return 'rare'\n",
    "    elif freq <= 100: return 'common'\n",
    "    else: return 'very_common'\n",
    "\n",
    "enhanced_quran['root_rarity'] = enhanced_quran['root_total_freq'].apply(classify_rarity)\n",
    "\n",
    "# Add revelation preference classification\n",
    "def classify_revelation_preference(ratio, total_freq):\n",
    "    if total_freq < 3: return 'insufficient_data'\n",
    "    elif ratio > 0.8: return 'strongly_meccan'\n",
    "    elif ratio > 0.6: return 'meccan_leaning'\n",
    "    elif ratio < 0.2: return 'strongly_medinan'\n",
    "    elif ratio < 0.4: return 'medinan_leaning'\n",
    "    else: return 'balanced'\n",
    "\n",
    "enhanced_quran['revelation_preference'] = enhanced_quran.apply(\n",
    "    lambda row: classify_revelation_preference(row['root_meccan_ratio'], row['root_total_freq']), axis=1\n",
    ")\n",
    "\n",
    "print(f\"✅ Enhanced dataset created with {len(enhanced_quran)} entries\")\n",
    "print(f\"New columns added: {[col for col in enhanced_quran.columns if col not in quran.columns]}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 7. Data Export and Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saving enhanced datasets...\n",
      "✅ Saved main enhanced dataset: quran-enhanced-phase1.csv\n",
      "✅ Saved frequency analysis: root-frequency-analysis.csv\n",
      "✅ Saved category analysis: semantic-category-analysis.csv\n",
      "✅ Saved co-occurrence matrices\n",
      "✅ Saved thematic distributions\n",
      "✅ Saved metadata summary: enhancement-metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Save enhanced datasets\n",
    "print(\"💾 Saving enhanced datasets...\")\n",
    "\n",
    "# Main enhanced dataset\n",
    "enhanced_quran.to_csv('quran-enhanced-phase1.csv', index=False)\n",
    "print(f\"✅ Saved main enhanced dataset: quran-enhanced-phase1.csv\")\n",
    "\n",
    "# Frequency statistics\n",
    "frequency_stats.to_csv('root-frequency-analysis.csv', index=False)\n",
    "print(f\"✅ Saved frequency analysis: root-frequency-analysis.csv\")\n",
    "\n",
    "# Semantic category analysis\n",
    "category_stats.to_csv('semantic-category-analysis.csv')\n",
    "print(f\"✅ Saved category analysis: semantic-category-analysis.csv\")\n",
    "\n",
    "# Co-occurrence matrices\n",
    "cooccurrence_df.to_csv('root-cooccurrence-matrix.csv', index=False)\n",
    "if not category_cooccurrence_df.empty:\n",
    "    category_cooccurrence_df.to_csv('category-cooccurrence-matrix.csv', index=False)\n",
    "    print(f\"✅ Saved co-occurrence matrices\")\n",
    "else:\n",
    "    # Save empty file with headers for consistency\n",
    "    pd.DataFrame(columns=['category1', 'category2', 'total_cooccurrence']).to_csv('category-cooccurrence-matrix.csv', index=False)\n",
    "    print(f\"✅ Saved root co-occurrence matrix (category matrix empty due to categorization issues)\")\n",
    "\n",
    "# Thematic distribution by sura\n",
    "sura_theme_distribution.to_csv('sura-thematic-distribution.csv')\n",
    "sura_theme_relative.to_csv('sura-thematic-relative.csv')\n",
    "print(f\"✅ Saved thematic distributions\")\n",
    "\n",
    "# Create metadata summary\n",
    "metadata_summary = {\n",
    "    'dataset_info': {\n",
    "        'total_entries': int(len(enhanced_quran)),\n",
    "        'entries_with_roots': int(enhanced_quran['Root'].notna().sum()),\n",
    "        'unique_roots': int(enhanced_quran['Root'].nunique()),\n",
    "        'enhancement_date': pd.Timestamp.now().isoformat()\n",
    "    },\n",
    "    'semantic_categories': list(semantic_categories.keys()),\n",
    "    'frequency_statistics': {\n",
    "        'most_frequent_root': str(frequency_stats.iloc[0]['root']),\n",
    "        'most_frequent_count': int(frequency_stats.iloc[0]['total_frequency']),\n",
    "        'hapax_legomena_count': int(len(frequency_stats[frequency_stats['total_frequency'] == 1])),\n",
    "        'rare_roots_count': int(len(frequency_stats[frequency_stats['total_frequency'] <= 5]))\n",
    "    },\n",
    "    'co_occurrence_stats': {\n",
    "        'unique_pairs': int(len(cooccurrence_df)),\n",
    "        'total_co_occurrences': int(total_pairs),\n",
    "        'top_pair': [str(cooccurrence_df.iloc[0]['root1']), str(cooccurrence_df.iloc[0]['root2'])],\n",
    "        'top_pair_count': int(cooccurrence_df.iloc[0]['cooccurrence_count'])\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('enhancement-metadata.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata_summary, f, indent=2, ensure_ascii=False)\n",
    "print(f\"✅ Saved metadata summary: enhancement-metadata.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 PHASE 1 ENHANCEMENT SUMMARY\n",
      "==================================================\n",
      "\n",
      "📊 Dataset Enhancements:\n",
      "  Original entries: 128,219\n",
      "  Enhanced entries: 128,219\n",
      "  New metadata columns: 9\n",
      "\n",
      "🎯 Semantic Analysis:\n",
      "  Categories defined: 15\n",
      "  Roots categorized: 133\n",
      "  Category coverage: 10.8%\n",
      "\n",
      "📈 Frequency Analysis:\n",
      "  Unique roots analyzed: 1642\n",
      "  Hapax legomena: 395\n",
      "  Strongly Meccan roots: 179\n",
      "  Strongly Medinan roots: 50\n",
      "\n",
      "🔗 Co-occurrence Analysis:\n",
      "  Verses analyzed: 6214\n",
      "  Root pairs found: 74185\n",
      "  Category pairs: 120\n",
      "\n",
      "💾 Files Created:\n",
      "  ✅ quran-enhanced-phase1.csv\n",
      "  ✅ root-frequency-analysis.csv\n",
      "  ✅ semantic-category-analysis.csv\n",
      "  ✅ root-cooccurrence-matrix.csv\n",
      "  ✅ category-cooccurrence-matrix.csv\n",
      "  ✅ sura-thematic-distribution.csv\n",
      "  ✅ sura-thematic-relative.csv\n",
      "  ✅ enhancement-metadata.json\n",
      "\n",
      "🚀 Ready for Phase 2: Backend API Development\n",
      "\n",
      "✨ Phase 1 Enhancement Complete! ✨\n"
     ]
    }
   ],
   "source": [
    "# Final comprehensive summary\n",
    "print(\"📋 PHASE 1 ENHANCEMENT SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\n📊 Dataset Enhancements:\")\n",
    "print(f\"  Original entries: {len(quran):,}\")\n",
    "print(f\"  Enhanced entries: {len(enhanced_quran):,}\")\n",
    "print(f\"  New metadata columns: {len(enhanced_quran.columns) - len(quran.columns)}\")\n",
    "\n",
    "print(f\"\\n🎯 Semantic Analysis:\")\n",
    "print(f\"  Categories defined: {len(semantic_categories)}\")\n",
    "print(f\"  Roots categorized: {sum(len(roots) for roots in semantic_categories.values())}\")\n",
    "print(f\"  Category coverage: {(enhanced_quran['semantic_category'] != 'uncategorized').sum() / len(enhanced_quran) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\n📈 Frequency Analysis:\")\n",
    "print(f\"  Unique roots analyzed: {len(frequency_stats)}\")\n",
    "print(f\"  Hapax legomena: {len(frequency_stats[frequency_stats['total_frequency'] == 1])}\")\n",
    "print(f\"  Strongly Meccan roots: {len(meccan_preferred)}\")\n",
    "print(f\"  Strongly Medinan roots: {len(medinan_preferred)}\")\n",
    "\n",
    "print(f\"\\n🔗 Co-occurrence Analysis:\")\n",
    "print(f\"  Verses analyzed: {len(verse_roots)}\")\n",
    "print(f\"  Root pairs found: {len(cooccurrence_df)}\")\n",
    "print(f\"  Category pairs: {len(category_cooccurrence_df)}\")\n",
    "\n",
    "print(f\"\\n💾 Files Created:\")\n",
    "files_created = [\n",
    "    'quran-enhanced-phase1.csv',\n",
    "    'root-frequency-analysis.csv', \n",
    "    'semantic-category-analysis.csv',\n",
    "    'root-cooccurrence-matrix.csv',\n",
    "    'category-cooccurrence-matrix.csv',\n",
    "    'sura-thematic-distribution.csv',\n",
    "    'sura-thematic-relative.csv',\n",
    "    'enhancement-metadata.json'\n",
    "]\n",
    "for file in files_created:\n",
    "    print(f\"  ✅ {file}\")\n",
    "\n",
    "print(f\"\\n🚀 Ready for Phase 2: Backend API Development\")\n",
    "print(f\"\\n✨ Phase 1 Enhancement Complete! ✨\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
