{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting the file of quran segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a [previous](http://abdulbaqi.io/2019/01/15/quranic_roots/) post I explored some of `Linux` commands to find root words in the entire Quran or in a particular sura of the Quran.\n",
    "\n",
    "While, `Linux` commands could be very productive at certain cases, they are not meant for data analysis. Hence, we need to resort to a proper data science programming language like R or Python. \n",
    "\n",
    "In this post, I will explore the power of `Python` to address a the same topc (i.e., root words in the Quran) but will extend the problem to much more interesting queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This post is not intended to be a beginner's tutorial to either `python` or `pandas` the special python package for data analysis that I will use here. I expect you to have some experience with both but more on python. I will assume you have less experince with `pandas` though. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without further ado, let us get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us start with few setup steps, like loading the `pandas` package and rename it for ease of usage as `pd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, read the file that contains the morphological information. Pandas has the `read_csv` function that can read directly from a URL. Note that the file contains some copyright information in the first 56 lines, and hence I am using `skiprows` option. Also, note that `read_csv` by defualt assumes the seperator to be a comman, if not -as is the case in this file- we need to explicitly specify the delimiter and hence the `sep='\\t'` option. Finally, we are displaying few lines from the top by the `head()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>FORM</th>\n",
       "      <th>TAG</th>\n",
       "      <th>FEATURES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1:1:1:1)</td>\n",
       "      <td>bi</td>\n",
       "      <td>P</td>\n",
       "      <td>PREFIX|bi+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1:1:1:2)</td>\n",
       "      <td>somi</td>\n",
       "      <td>N</td>\n",
       "      <td>STEM|POS:N|LEM:{som|ROOT:smw|M|GEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1:1:2:1)</td>\n",
       "      <td>{ll~ahi</td>\n",
       "      <td>PN</td>\n",
       "      <td>STEM|POS:PN|LEM:{ll~ah|ROOT:Alh|GEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1:1:3:1)</td>\n",
       "      <td>{l</td>\n",
       "      <td>DET</td>\n",
       "      <td>PREFIX|Al+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1:1:3:2)</td>\n",
       "      <td>r~aHoma`ni</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>STEM|POS:ADJ|LEM:r~aHoma`n|ROOT:rHm|MS|GEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LOCATION        FORM  TAG                                    FEATURES\n",
       "0  (1:1:1:1)          bi    P                                  PREFIX|bi+\n",
       "1  (1:1:1:2)        somi    N          STEM|POS:N|LEM:{som|ROOT:smw|M|GEN\n",
       "2  (1:1:2:1)     {ll~ahi   PN         STEM|POS:PN|LEM:{ll~ah|ROOT:Alh|GEN\n",
       "3  (1:1:3:1)          {l  DET                                  PREFIX|Al+\n",
       "4  (1:1:3:2)  r~aHoma`ni  ADJ  STEM|POS:ADJ|LEM:r~aHoma`n|ROOT:rHm|MS|GEN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://textminingthequran.com/data/quranic-corpus-morphology-0.4.txt'\n",
    "qdforiginal = pd.read_csv(url, sep='\\t',skiprows=56)\n",
    "qdforiginal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good idea to save the first version locally by the `to_csv()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdforiginal.to_csv('quran-morphology-v1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the first few lines of the file above we see that the `LOCATION` and `FEATURES` columns need to be split further. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our file contains 128k lines (you can verify that by the command `qdforiginal.shape`). I prefer to take a small sample of this big file and run the experimentations of splitting. When successful, we can then run it on the entire file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is my strategy: since I am interested on root words, I want to select first all rows that contain the word `ROOT:` in the `FEATURES` column. This can be done by a command like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2     True\n",
       "Name: FEATURES, dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdforiginal.FEATURES.str.contains('ROOT')[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I only took the first 3 lines of the entire 128k lines. It returns `boolean` values of `True` or `False`. So, we can pass this boolean result to filter the entire dataframe by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>FORM</th>\n",
       "      <th>TAG</th>\n",
       "      <th>FEATURES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1:1:1:2)</td>\n",
       "      <td>somi</td>\n",
       "      <td>N</td>\n",
       "      <td>STEM|POS:N|LEM:{som|ROOT:smw|M|GEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1:1:2:1)</td>\n",
       "      <td>{ll~ahi</td>\n",
       "      <td>PN</td>\n",
       "      <td>STEM|POS:PN|LEM:{ll~ah|ROOT:Alh|GEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1:1:3:2)</td>\n",
       "      <td>r~aHoma`ni</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>STEM|POS:ADJ|LEM:r~aHoma`n|ROOT:rHm|MS|GEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LOCATION        FORM  TAG                                    FEATURES\n",
       "1  (1:1:1:2)        somi    N          STEM|POS:N|LEM:{som|ROOT:smw|M|GEN\n",
       "2  (1:1:2:1)     {ll~ahi   PN         STEM|POS:PN|LEM:{ll~ah|ROOT:Alh|GEN\n",
       "4  (1:1:3:2)  r~aHoma`ni  ADJ  STEM|POS:ADJ|LEM:r~aHoma`n|ROOT:rHm|MS|GEN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdforiginal[qdforiginal.FEATURES.str.contains('ROOT:')].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure some random sampling, I can always use `sample()` method as follows. I will name this sample as `qsample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>FORM</th>\n",
       "      <th>TAG</th>\n",
       "      <th>FEATURES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75915</th>\n",
       "      <td>(24:41:11:3)</td>\n",
       "      <td>T~ayoru</td>\n",
       "      <td>N</td>\n",
       "      <td>STEM|POS:N|LEM:Tayor|ROOT:Tyr|M|NOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21576</th>\n",
       "      <td>(4:159:14:1)</td>\n",
       "      <td>$ahiydFA</td>\n",
       "      <td>N</td>\n",
       "      <td>STEM|POS:N|LEM:$ahiyd|ROOT:$hd|MS|INDEF|ACC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63776</th>\n",
       "      <td>(18:52:7:2)</td>\n",
       "      <td>daEa</td>\n",
       "      <td>V</td>\n",
       "      <td>STEM|POS:V|PERF|LEM:daEaA|ROOT:dEw|3MP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108439</th>\n",
       "      <td>(47:3:17:3)</td>\n",
       "      <td>n~aAsi</td>\n",
       "      <td>N</td>\n",
       "      <td>STEM|POS:N|LEM:n~aAs|ROOT:nws|MP|GEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78890</th>\n",
       "      <td>(26:60:2:1)</td>\n",
       "      <td>m~u$oriqiyna</td>\n",
       "      <td>N</td>\n",
       "      <td>STEM|POS:N|ACT|PCPL|(IV)|LEM:m~u$oriqiyn|ROOT:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127444</th>\n",
       "      <td>(97:4:3:3)</td>\n",
       "      <td>r~uwHu</td>\n",
       "      <td>N</td>\n",
       "      <td>STEM|POS:N|LEM:ruwH|ROOT:rwH|M|NOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78895</th>\n",
       "      <td>(26:61:3:2)</td>\n",
       "      <td>jamoEaAni</td>\n",
       "      <td>N</td>\n",
       "      <td>STEM|POS:N|LEM:jamoE|ROOT:jmE|MD|NOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109979</th>\n",
       "      <td>(48:25:28:1)</td>\n",
       "      <td>{ll~ahu</td>\n",
       "      <td>PN</td>\n",
       "      <td>STEM|POS:PN|LEM:{ll~ah|ROOT:Alh|NOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51559</th>\n",
       "      <td>(12:62:12:1)</td>\n",
       "      <td>&gt;aholi</td>\n",
       "      <td>N</td>\n",
       "      <td>STEM|POS:N|LEM:&gt;ahol|ROOT:Ahl|M|GEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46582</th>\n",
       "      <td>(10:100:10:2)</td>\n",
       "      <td>r~ijosa</td>\n",
       "      <td>N</td>\n",
       "      <td>STEM|POS:N|LEM:rijos|ROOT:rjs|M|ACC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LOCATION          FORM TAG  \\\n",
       "75915    (24:41:11:3)       T~ayoru   N   \n",
       "21576    (4:159:14:1)      $ahiydFA   N   \n",
       "63776     (18:52:7:2)          daEa   V   \n",
       "108439    (47:3:17:3)        n~aAsi   N   \n",
       "78890     (26:60:2:1)  m~u$oriqiyna   N   \n",
       "127444     (97:4:3:3)        r~uwHu   N   \n",
       "78895     (26:61:3:2)     jamoEaAni   N   \n",
       "109979   (48:25:28:1)       {ll~ahu  PN   \n",
       "51559    (12:62:12:1)        >aholi   N   \n",
       "46582   (10:100:10:2)       r~ijosa   N   \n",
       "\n",
       "                                                 FEATURES  \n",
       "75915                 STEM|POS:N|LEM:Tayor|ROOT:Tyr|M|NOM  \n",
       "21576         STEM|POS:N|LEM:$ahiyd|ROOT:$hd|MS|INDEF|ACC  \n",
       "63776              STEM|POS:V|PERF|LEM:daEaA|ROOT:dEw|3MP  \n",
       "108439               STEM|POS:N|LEM:n~aAs|ROOT:nws|MP|GEN  \n",
       "78890   STEM|POS:N|ACT|PCPL|(IV)|LEM:m~u$oriqiyn|ROOT:...  \n",
       "127444                 STEM|POS:N|LEM:ruwH|ROOT:rwH|M|NOM  \n",
       "78895                STEM|POS:N|LEM:jamoE|ROOT:jmE|MD|NOM  \n",
       "109979                STEM|POS:PN|LEM:{ll~ah|ROOT:Alh|NOM  \n",
       "51559                 STEM|POS:N|LEM:>ahol|ROOT:Ahl|M|GEN  \n",
       "46582                 STEM|POS:N|LEM:rijos|ROOT:rjs|M|ACC  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qsample = qdforiginal[qdforiginal.FEATURES.str.contains('ROOT:')].sample(10); qsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My intention is to split the `LOCATION` column into four columns, and then the `FEATURES` column into a column for Root and another for Lemma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I am going to split the first column `LOCATION` into four columns. This is done through the `extract` function of the string which can take a `regular expression`. The `?P<...>` construct within the regular expression creates columns with these names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sura</th>\n",
       "      <th>aya</th>\n",
       "      <th>word</th>\n",
       "      <th>w_seg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75915</th>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21576</th>\n",
       "      <td>4</td>\n",
       "      <td>159</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63776</th>\n",
       "      <td>18</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108439</th>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78890</th>\n",
       "      <td>26</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127444</th>\n",
       "      <td>97</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78895</th>\n",
       "      <td>26</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109979</th>\n",
       "      <td>48</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51559</th>\n",
       "      <td>12</td>\n",
       "      <td>62</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46582</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sura  aya word w_seg\n",
       "75915    24   41   11     3\n",
       "21576     4  159   14     1\n",
       "63776    18   52    7     2\n",
       "108439   47    3   17     3\n",
       "78890    26   60    2     1\n",
       "127444   97    4    3     3\n",
       "78895    26   61    3     2\n",
       "109979   48   25   28     1\n",
       "51559    12   62   12     1\n",
       "46582    10  100   10     2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp1 = qsample.LOCATION.str.extract(r'(?P<sura>\\d*):(?P<aya>\\d*):(?P<word>\\d*):(?P<w_seg>\\d*)'); tmp1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us extract the roots from the `FEATURES` column in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75915</th>\n",
       "      <td>Tyr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21576</th>\n",
       "      <td>$hd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63776</th>\n",
       "      <td>dEw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108439</th>\n",
       "      <td>nws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78890</th>\n",
       "      <td>$rq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127444</th>\n",
       "      <td>rwH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78895</th>\n",
       "      <td>jmE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109979</th>\n",
       "      <td>Alh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51559</th>\n",
       "      <td>Ahl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46582</th>\n",
       "      <td>rjs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Root\n",
       "75915   Tyr\n",
       "21576   $hd\n",
       "63776   dEw\n",
       "108439  nws\n",
       "78890   $rq\n",
       "127444  rwH\n",
       "78895   jmE\n",
       "109979  Alh\n",
       "51559   Ahl\n",
       "46582   rjs"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp2 = qsample.FEATURES.str.extract(r'ROOT:(?P<Root>[^|]*)'); tmp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, I want to extract **Lemmas** as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75915</th>\n",
       "      <td>Tayor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21576</th>\n",
       "      <td>$ahiyd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63776</th>\n",
       "      <td>daEaA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108439</th>\n",
       "      <td>n~aAs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78890</th>\n",
       "      <td>m~u$oriqiyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127444</th>\n",
       "      <td>ruwH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78895</th>\n",
       "      <td>jamoE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109979</th>\n",
       "      <td>{ll~ah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51559</th>\n",
       "      <td>&gt;ahol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46582</th>\n",
       "      <td>rijos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Lemma\n",
       "75915         Tayor\n",
       "21576        $ahiyd\n",
       "63776         daEaA\n",
       "108439        n~aAs\n",
       "78890   m~u$oriqiyn\n",
       "127444         ruwH\n",
       "78895         jamoE\n",
       "109979       {ll~ah\n",
       "51559         >ahol\n",
       "46582         rijos"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp3 = qsample.FEATURES.str.extract(r'LEM:(?P<Lemma>[^|]*)'); tmp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, all that is left is to cancatenate the orginal sample `qsample` with these three splits `tmp1, tmp2, tmp3`, as follows. The `axis=1` option means that run the concatenation on columns (not rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sura</th>\n",
       "      <th>aya</th>\n",
       "      <th>word</th>\n",
       "      <th>w_seg</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>FORM</th>\n",
       "      <th>TAG</th>\n",
       "      <th>FEATURES</th>\n",
       "      <th>Root</th>\n",
       "      <th>Lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75915</th>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>(24:41:11:3)</td>\n",
       "      <td>T~ayoru</td>\n",
       "      <td>N</td>\n",
       "      <td>STEM|POS:N|LEM:Tayor|ROOT:Tyr|M|NOM</td>\n",
       "      <td>Tyr</td>\n",
       "      <td>Tayor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21576</th>\n",
       "      <td>4</td>\n",
       "      <td>159</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>(4:159:14:1)</td>\n",
       "      <td>$ahiydFA</td>\n",
       "      <td>N</td>\n",
       "      <td>STEM|POS:N|LEM:$ahiyd|ROOT:$hd|MS|INDEF|ACC</td>\n",
       "      <td>$hd</td>\n",
       "      <td>$ahiyd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63776</th>\n",
       "      <td>18</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>(18:52:7:2)</td>\n",
       "      <td>daEa</td>\n",
       "      <td>V</td>\n",
       "      <td>STEM|POS:V|PERF|LEM:daEaA|ROOT:dEw|3MP</td>\n",
       "      <td>dEw</td>\n",
       "      <td>daEaA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108439</th>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>(47:3:17:3)</td>\n",
       "      <td>n~aAsi</td>\n",
       "      <td>N</td>\n",
       "      <td>STEM|POS:N|LEM:n~aAs|ROOT:nws|MP|GEN</td>\n",
       "      <td>nws</td>\n",
       "      <td>n~aAs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78890</th>\n",
       "      <td>26</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>(26:60:2:1)</td>\n",
       "      <td>m~u$oriqiyna</td>\n",
       "      <td>N</td>\n",
       "      <td>STEM|POS:N|ACT|PCPL|(IV)|LEM:m~u$oriqiyn|ROOT:...</td>\n",
       "      <td>$rq</td>\n",
       "      <td>m~u$oriqiyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127444</th>\n",
       "      <td>97</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>(97:4:3:3)</td>\n",
       "      <td>r~uwHu</td>\n",
       "      <td>N</td>\n",
       "      <td>STEM|POS:N|LEM:ruwH|ROOT:rwH|M|NOM</td>\n",
       "      <td>rwH</td>\n",
       "      <td>ruwH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78895</th>\n",
       "      <td>26</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>(26:61:3:2)</td>\n",
       "      <td>jamoEaAni</td>\n",
       "      <td>N</td>\n",
       "      <td>STEM|POS:N|LEM:jamoE|ROOT:jmE|MD|NOM</td>\n",
       "      <td>jmE</td>\n",
       "      <td>jamoE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109979</th>\n",
       "      <td>48</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>(48:25:28:1)</td>\n",
       "      <td>{ll~ahu</td>\n",
       "      <td>PN</td>\n",
       "      <td>STEM|POS:PN|LEM:{ll~ah|ROOT:Alh|NOM</td>\n",
       "      <td>Alh</td>\n",
       "      <td>{ll~ah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51559</th>\n",
       "      <td>12</td>\n",
       "      <td>62</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>(12:62:12:1)</td>\n",
       "      <td>&gt;aholi</td>\n",
       "      <td>N</td>\n",
       "      <td>STEM|POS:N|LEM:&gt;ahol|ROOT:Ahl|M|GEN</td>\n",
       "      <td>Ahl</td>\n",
       "      <td>&gt;ahol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46582</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>(10:100:10:2)</td>\n",
       "      <td>r~ijosa</td>\n",
       "      <td>N</td>\n",
       "      <td>STEM|POS:N|LEM:rijos|ROOT:rjs|M|ACC</td>\n",
       "      <td>rjs</td>\n",
       "      <td>rijos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sura  aya word w_seg       LOCATION          FORM TAG  \\\n",
       "75915    24   41   11     3   (24:41:11:3)       T~ayoru   N   \n",
       "21576     4  159   14     1   (4:159:14:1)      $ahiydFA   N   \n",
       "63776    18   52    7     2    (18:52:7:2)          daEa   V   \n",
       "108439   47    3   17     3    (47:3:17:3)        n~aAsi   N   \n",
       "78890    26   60    2     1    (26:60:2:1)  m~u$oriqiyna   N   \n",
       "127444   97    4    3     3     (97:4:3:3)        r~uwHu   N   \n",
       "78895    26   61    3     2    (26:61:3:2)     jamoEaAni   N   \n",
       "109979   48   25   28     1   (48:25:28:1)       {ll~ahu  PN   \n",
       "51559    12   62   12     1   (12:62:12:1)        >aholi   N   \n",
       "46582    10  100   10     2  (10:100:10:2)       r~ijosa   N   \n",
       "\n",
       "                                                 FEATURES Root        Lemma  \n",
       "75915                 STEM|POS:N|LEM:Tayor|ROOT:Tyr|M|NOM  Tyr        Tayor  \n",
       "21576         STEM|POS:N|LEM:$ahiyd|ROOT:$hd|MS|INDEF|ACC  $hd       $ahiyd  \n",
       "63776              STEM|POS:V|PERF|LEM:daEaA|ROOT:dEw|3MP  dEw        daEaA  \n",
       "108439               STEM|POS:N|LEM:n~aAs|ROOT:nws|MP|GEN  nws        n~aAs  \n",
       "78890   STEM|POS:N|ACT|PCPL|(IV)|LEM:m~u$oriqiyn|ROOT:...  $rq  m~u$oriqiyn  \n",
       "127444                 STEM|POS:N|LEM:ruwH|ROOT:rwH|M|NOM  rwH         ruwH  \n",
       "78895                STEM|POS:N|LEM:jamoE|ROOT:jmE|MD|NOM  jmE        jamoE  \n",
       "109979                STEM|POS:PN|LEM:{ll~ah|ROOT:Alh|NOM  Alh       {ll~ah  \n",
       "51559                 STEM|POS:N|LEM:>ahol|ROOT:Ahl|M|GEN  Ahl        >ahol  \n",
       "46582                 STEM|POS:N|LEM:rijos|ROOT:rjs|M|ACC  rjs        rijos  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([tmp1, qsample, tmp2,tmp3], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we ran the experiment successfully with the sample, let us repeat it on the actual file `qdforiginal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = qdforiginal.LOCATION.str.extract(r'(?P<sura>\\d*):(?P<aya>\\d*):(?P<word>\\d*):(?P<w_seg>\\d*)')\n",
    "tmp2 = qdforiginal.FEATURES.str.extract(r'ROOT:(?P<Root>[^|]*)')\n",
    "tmp3 = qdforiginal.FEATURES.str.extract(r'LEM:(?P<Lemma>[^|]*)')\n",
    "df_qruan = pd.concat([tmp1, qdforiginal, tmp2,tmp3], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm the shape of the new dataframe `df_qruan` I can use the `shape` attribute, also I can display randomly some rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128219, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qruan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sura</th>\n",
       "      <th>aya</th>\n",
       "      <th>word</th>\n",
       "      <th>w_seg</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>FORM</th>\n",
       "      <th>TAG</th>\n",
       "      <th>FEATURES</th>\n",
       "      <th>Root</th>\n",
       "      <th>Lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81748</th>\n",
       "      <td>27</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>(27:63:4:1)</td>\n",
       "      <td>Zuluma`ti</td>\n",
       "      <td>N</td>\n",
       "      <td>STEM|POS:N|LEM:Zuluma`t|ROOT:Zlm|FP|GEN</td>\n",
       "      <td>Zlm</td>\n",
       "      <td>Zuluma`t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107753</th>\n",
       "      <td>46</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>(46:16:8:1)</td>\n",
       "      <td>wa</td>\n",
       "      <td>CONJ</td>\n",
       "      <td>PREFIX|w:CONJ+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83638</th>\n",
       "      <td>28</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>(28:49:2:2)</td>\n",
       "      <td>&gt;otu</td>\n",
       "      <td>V</td>\n",
       "      <td>STEM|POS:V|IMPV|LEM:&gt;ataY|ROOT:Aty|2MP</td>\n",
       "      <td>Aty</td>\n",
       "      <td>&gt;ataY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97849</th>\n",
       "      <td>38</td>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>(38:78:4:1)</td>\n",
       "      <td>&lt;ilaY`</td>\n",
       "      <td>P</td>\n",
       "      <td>STEM|POS:P|LEM:&lt;ilaY`</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;ilaY`</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73247</th>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>(23:27:8:2)</td>\n",
       "      <td>&lt;i*aA</td>\n",
       "      <td>T</td>\n",
       "      <td>STEM|POS:T|LEM:&lt;i*aA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;i*aA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sura aya word w_seg     LOCATION       FORM   TAG  \\\n",
       "81748    27  63    4     1  (27:63:4:1)  Zuluma`ti     N   \n",
       "107753   46  16    8     1  (46:16:8:1)         wa  CONJ   \n",
       "83638    28  49    2     2  (28:49:2:2)       >otu     V   \n",
       "97849    38  78    4     1  (38:78:4:1)     <ilaY`     P   \n",
       "73247    23  27    8     2  (23:27:8:2)      <i*aA     T   \n",
       "\n",
       "                                       FEATURES Root     Lemma  \n",
       "81748   STEM|POS:N|LEM:Zuluma`t|ROOT:Zlm|FP|GEN  Zlm  Zuluma`t  \n",
       "107753                           PREFIX|w:CONJ+  NaN       NaN  \n",
       "83638    STEM|POS:V|IMPV|LEM:>ataY|ROOT:Aty|2MP  Aty     >ataY  \n",
       "97849                     STEM|POS:P|LEM:<ilaY`  NaN    <ilaY`  \n",
       "73247                      STEM|POS:T|LEM:<i*aA  NaN     <i*aA  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qruan.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It could be possible that our newly introduced columns could have extra spaces which we can get rid of by using the `strip()` method of string as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qruan.Root = df_qruan.Root.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qruan.Lemma = df_qruan.Lemma.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is good idea to save this version into a `csv` file. `index=False` avoids unncessesarity including an extra index column in the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qruan.to_csv('quran-morphology-v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## join with Meccan/Medinan file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be very useful to augment our file with a new column that tells me if a sura is Meccan or Medinan. This will later allow to answer question like, **what are the unique root words in the Quran that appear only in Meccan sura?** for example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, I am referring to a table of contents page I created some time back using `Angular` [here](http://textminingthequran.com/toc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My idea is to go that page, and use mouse to select the table, copy it in the clipboard and then perform the following operation to read the clipboard and create a dataframe `qtoc` as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtoc=pd.read_csv('toc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>Name Arabic</th>\n",
       "      <th>Name</th>\n",
       "      <th>English Meaning</th>\n",
       "      <th>No of verses</th>\n",
       "      <th>Place</th>\n",
       "      <th>Chronology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>الفاتحة</td>\n",
       "      <td>Al-Fatiha</td>\n",
       "      <td>The Opening</td>\n",
       "      <td>7</td>\n",
       "      <td>Meccan</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>البقرة</td>\n",
       "      <td>Al-Baqara</td>\n",
       "      <td>The Cow</td>\n",
       "      <td>286</td>\n",
       "      <td>Medinan</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>آل عمران</td>\n",
       "      <td>Al Imran</td>\n",
       "      <td>The House of Joachim</td>\n",
       "      <td>200</td>\n",
       "      <td>Medinan</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>النساء</td>\n",
       "      <td>An-Nisa'</td>\n",
       "      <td>Women</td>\n",
       "      <td>176</td>\n",
       "      <td>Medinan</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>المائدة</td>\n",
       "      <td>Al-Ma'ida</td>\n",
       "      <td>The Table Spread</td>\n",
       "      <td>120</td>\n",
       "      <td>Medinan</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No. Name Arabic       Name       English Meaning  No of verses    Place  \\\n",
       "0    1     الفاتحة  Al-Fatiha           The Opening             7   Meccan   \n",
       "1    2      البقرة  Al-Baqara               The Cow           286  Medinan   \n",
       "2    3    آل عمران   Al Imran  The House of Joachim           200  Medinan   \n",
       "3    4      النساء   An-Nisa'                 Women           176  Medinan   \n",
       "4    5     المائدة  Al-Ma'ida      The Table Spread           120  Medinan   \n",
       "\n",
       "   Chronology  \n",
       "0           5  \n",
       "1          87  \n",
       "2          89  \n",
       "3          92  \n",
       "4         112  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtoc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let me save this dataframe locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtoc.to_csv('toc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now use the `merge` function to merge our original file `df_qruan` with the `qtoc` on the sura number (which is `sura` in the left `df_qruan` file and `No.` column in the right `qtoc` file. The `left` join is the one that makes sense here. The new dataframe is saved in a `quran`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and int64 columns for key 'sura'. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m quran = \u001b[43mdf_qruan\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqtoc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mNo.\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPlace\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mleft\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msura\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mNo.\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10839\u001b[39m, in \u001b[36mDataFrame.merge\u001b[39m\u001b[34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m  10820\u001b[39m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m  10821\u001b[39m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents=\u001b[32m2\u001b[39m)\n\u001b[32m  10822\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mmerge\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m  10835\u001b[39m     validate: MergeValidate | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  10836\u001b[39m ) -> DataFrame:\n\u001b[32m  10837\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[32m> \u001b[39m\u001b[32m10839\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  10840\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m  10841\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10843\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10845\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10846\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10848\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10849\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10850\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10851\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10852\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10853\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:170\u001b[39m, in \u001b[36mmerge\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[32m    156\u001b[39m         left_df,\n\u001b[32m    157\u001b[39m         right_df,\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         copy=copy,\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     op = \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result(copy=copy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:807\u001b[39m, in \u001b[36m_MergeOperation.__init__\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    803\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_tolerance(\u001b[38;5;28mself\u001b[39m.left_join_keys)\n\u001b[32m    805\u001b[39m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[32m    806\u001b[39m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m807\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    809\u001b[39m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[32m    810\u001b[39m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[32m    811\u001b[39m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[32m    812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1508\u001b[39m, in \u001b[36m_MergeOperation._maybe_coerce_merge_keys\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1502\u001b[39m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[32m   1503\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m   1504\u001b[39m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[32m   1505\u001b[39m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1506\u001b[39m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[32m   1507\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1508\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1510\u001b[39m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk.dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk.dtype):\n",
      "\u001b[31mValueError\u001b[39m: You are trying to merge on object and int64 columns for key 'sura'. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "quran = df_qruan.merge(qtoc.loc[:,['No.', 'Place']], how='left', left_on='sura', right_on='No.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can display few useful information through the `info()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quran.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed that I no longer need the `LOCATION` and `No.` column as they are now redundent. So, just drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quran.drop(columns=['LOCATION','No.'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, here is a local copy of the final file after doing all these setup steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quran.to_csv('quran-morphology-final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## converting Buckwalter to Arabic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our file contains Quranic words and roots in Buckwalter form, and I wanted a handy function to convert that into Arabic form. Here is how we do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, referencing [this](http://corpus.quran.com/java/buckwalter.jsp) site, I can construct the followig dictionary of all mappings of unicode symbols into buckwalter as follows. I will call this dictionary `abjad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abjad = {u\"\\u0627\":'A',\n",
    "u\"\\u0628\":'b', u\"\\u062A\":'t', u\"\\u062B\":'v', u\"\\u062C\":'j',\n",
    "u\"\\u062D\":'H', u\"\\u062E\":'x', u\"\\u062F\":'d', u\"\\u0630\":'*', u\"\\u0631\":'r',\n",
    "u\"\\u0632\":'z', u\"\\u0633\":'s', u\"\\u0634\":'$', u\"\\u0635\":'S', u\"\\u0636\":'D',\n",
    "u\"\\u0637\":'T', u\"\\u0638\":'Z', u\"\\u0639\":'E', u\"\\u063A\":'g', u\"\\u0641\":'f',\n",
    "u\"\\u0642\":'q', u\"\\u0643\":'k', u\"\\u0644\":'l', u\"\\u0645\":'m', u\"\\u0646\":'n',\n",
    "u\"\\u0647\":'h', u\"\\u0648\":'w', u\"\\u0649\":'Y', u\"\\u064A\":'y'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abjad[' ']=' '\n",
    "abjad[u\"\\u0621\"] = '\\''\n",
    "abjad[u\"\\u0623\"] = '>'\n",
    "abjad[u\"\\u0625\"] = '<'\n",
    "abjad[u\"\\u0624\"] = '&'\n",
    "abjad[u\"\\u0626\"] = '}'\n",
    "#abjad[u\"\\u0655\"] = '\\'' # Hamza below\n",
    "abjad[u\"\\u0622\"] = '|'\n",
    "abjad[u\"\\u064E\"] = 'a'\n",
    "abjad[u\"\\u064F\"] = 'u'\n",
    "abjad[u\"\\u0650\"] = 'i'\n",
    "abjad[u\"\\u0651\"] = '~'\n",
    "abjad[u\"\\u0652\"] = 'o'\n",
    "abjad[u\"\\u064B\"] = 'F'\n",
    "abjad[u\"\\u064C\"] = 'N'\n",
    "abjad[u\"\\u064D\"] = 'K'\n",
    "abjad[u\"\\u0640\"] = '_'\n",
    "abjad[u\"\\u0670\"] = '`'\n",
    "abjad[u\"\\u0629\"] = 'p'\n",
    "abjad[u\"\\u0653\"] = '^'\n",
    "abjad[u\"\\u0654\"] = '#'\n",
    "abjad[u\"\\u0671\"] = '{'\n",
    "abjad[u\"\\u06DC\"] = ':'\n",
    "abjad[u\"\\u06DF\"] = '@'\n",
    "abjad[u\"\\u0653\"] = '^'\n",
    "abjad[u\"\\u06E0\"] = '\"'\n",
    "abjad[u\"\\u06E2\"] = '['\n",
    "abjad[u\"\\u06E3\"] = ';'\n",
    "abjad[u\"\\u06E5\"] = ','\n",
    "abjad[u\"\\u06E6\"] = '.'\n",
    "abjad[u\"\\u06E8\"] = '!'\n",
    "abjad[u\"\\u06EA\"] = '-'\n",
    "abjad[u\"\\u06EB\"] = '+'\n",
    "abjad[u\"\\u06EC\"] = '%'\n",
    "abjad[u\"\\u06ED\"] = ']'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also construct the reverse dictionary called `alphabet` that maps the bucwalter symbols back to unicode and hence can display Arabic words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the reverse\n",
    "alphabet = {}\n",
    "for key in abjad:\n",
    "    alphabet[abjad[key]] = key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these two dictionaries, we can always convert a string from one form to other using the following two handy functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arabic_to_buc(ara):\n",
    "    return ''.join(map(lambda x:abjad[x], list(ara)))\n",
    "\n",
    "def buck_to_arabic(buc):\n",
    "    return ''.join(map(lambda x:alphabet[x], list(buc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a small test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buck_to_arabic('EalaY`')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_to_buc('الحمد لله')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## counting roots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to get into the core of our query: **What are the unique root words that appear in Meccan sura, but not in the Medinan surah?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw before, we can: (1) filter a dataframe by logical checks like `quran.Place== 'Meccan'`. With that we (2) get set of all Meccan words, (3) then we select only the `Root` column, (4) then we run the `unique()` method to get an array of unique words which we can (5) then convert to list using `tolist()` function. Finally (6) we wrap the whole thing to a `set()` function, and hence we get the set of Meccan unique root words called `k` here. So, note how through chaining I could perform six operations into one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = set(quran[quran.Place == 'Meccan'].Root.unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same logic, we produce the unique list of Medinan words in a set called `d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = set(quran[quran.Place == 'Medinan'].Root.unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we can now remove the roots from Meccan list that are also in the Medinan, but the following set operation. We find out that there are 547 of such words, and 198 Medinan only words, and 898 root words appear in both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makki_words = k-d; len(makki_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "madani_words = d - k; len(madani_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both = k & d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(both)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have at our hand all nuts and bolts to define two useful functions as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first function is `sura_words`. It takes as input a list of sura numbers (for example `[113,114]` means sura 113 and 114). It also takes which kind of unique words we want to find for this list of sura: `W` is the default word list, `R` is the Root list and `L` is the Lemma list. Not how we use the `isin()` method to filter the dataframe on only the list of sura we provide. Also note the `dropna()` function to drop the `null` values from the list. Finally note how we are returnting Arabic form of the final resuls using the `buck_to_arabic()` function we defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return words given a list of sura\n",
    "def sura_words(s_list, kind='W'):\n",
    "    if (kind=='R'):\n",
    "        result = quran[quran.sura.isin(s_list)].Root.dropna().unique().tolist()\n",
    "    elif (kind=='L'):\n",
    "        result = quran[quran.sura.isin(s_list)].Lemma.dropna().unique().tolist()\n",
    "    else:\n",
    "        result = quran[quran.sura.isin(s_list)].FORM.unique().tolist()\n",
    "    return [buck_to_arabic(x) for x in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a test on `Lemma` words of suran No. 111."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sura_words([111],'L')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function can have lots of utilities. Among them you may want to increase your Quranic vocabulary gradually by memorizing roots of one sura at a time. This function conviniently will give you the unique list of roots (or lemmas, or just words)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a small variation and exploiting the set operations, we can define another function called `unique_sura_words` that again takes a list of sura and returns root (or lemma or raw words) that appears only in this list of suras. Note the `~` operator to negate a condition. So `~quran.sura.isin([113,114])` means all sura except 113 and 114. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return words given a list of sura\n",
    "def unique_sura_words(s_list, kind='W'):\n",
    "    if (kind=='R'):\n",
    "        first = quran[quran.sura.isin(s_list)].Root.dropna().unique().tolist()\n",
    "        second = quran[~quran.sura.isin(s_list)].Root.dropna().unique().tolist()\n",
    "        result = list(set(first)-set(second))\n",
    "    elif (kind=='L'):\n",
    "        first = quran[quran.sura.isin(s_list)].Lemma.dropna().unique().tolist()\n",
    "        second = quran[~quran.sura.isin(s_list)].Lemma.dropna().unique().tolist()\n",
    "        result = list(set(first)-set(second))\n",
    "    else:\n",
    "        first = quran[quran.sura.isin(s_list)].FORM.dropna().unique().tolist()\n",
    "        second = quran[~quran.sura.isin(s_list)].FORM.dropna().unique().tolist()\n",
    "        result = list(set(first)-set(second))\n",
    "    return [buck_to_arabic(x) for x in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this function we know that sura 113 has these two root words that can be found no where else in the Quran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sura_words([113],'R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
