{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Enhanced Quranic Root Words Analysis - Phase 1\n",
        "\n",
        "This notebook enhances the basic morphological analysis with:\n",
        "- **Semantic Metadata Layer**: Meaning categories and themes\n",
        "- **Frequency Analysis**: Statistical patterns and distributions\n",
        "- **Thematic Categorization**: Subject-based root groupings\n",
        "- **Co-occurrence Matrices**: Root relationship networks\n",
        "\n",
        "Building upon the foundation from `quran_corrected.ipynb`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enhanced imports for advanced analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter, defaultdict\n",
        "import networkx as nx\n",
        "from itertools import combinations\n",
        "import json\n",
        "from functools import lru_cache\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"üìö Enhanced libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Load and Prepare Base Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the processed data from previous analysis\n",
        "print(\"üì• Loading processed Quranic data...\")\n",
        "try:\n",
        "    quran = pd.read_csv('quran-morphology-final.csv')\n",
        "    print(f\"‚úÖ Loaded {len(quran):,} entries\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå Base data file not found. Please run quran_corrected.ipynb first.\")\n",
        "    raise\n",
        "\n",
        "# Load table of contents\n",
        "toc = pd.read_csv('toc.csv')\n",
        "print(f\"‚úÖ Loaded TOC with {len(toc)} suras\")\n",
        "\n",
        "# Display basic info\n",
        "print(f\"\\nüìä Dataset Overview:\")\n",
        "print(f\"Total entries: {len(quran):,}\")\n",
        "print(f\"Entries with roots: {quran.Root.notna().sum():,}\")\n",
        "print(f\"Unique roots: {quran.Root.nunique():,}\")\n",
        "print(f\"Meccan suras: {len(toc[toc.Place == 'Meccan'])}\")\n",
        "print(f\"Medinan suras: {len(toc[toc.Place == 'Medinan'])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up Buckwalter conversion functions (from previous notebook)\n",
        "abjad = {\n",
        "    \"\\u0627\": 'A', \"\\u0628\": 'b', \"\\u062A\": 't', \"\\u062B\": 'v', \"\\u062C\": 'j',\n",
        "    \"\\u062D\": 'H', \"\\u062E\": 'x', \"\\u062F\": 'd', \"\\u0630\": '*', \"\\u0631\": 'r',\n",
        "    \"\\u0632\": 'z', \"\\u0633\": 's', \"\\u0634\": '$', \"\\u0635\": 'S', \"\\u0636\": 'D',\n",
        "    \"\\u0637\": 'T', \"\\u0638\": 'Z', \"\\u0639\": 'E', \"\\u063A\": 'g', \"\\u0641\": 'f',\n",
        "    \"\\u0642\": 'q', \"\\u0643\": 'k', \"\\u0644\": 'l', \"\\u0645\": 'm', \"\\u0646\": 'n',\n",
        "    \"\\u0647\": 'h', \"\\u0648\": 'w', \"\\u0649\": 'Y', \"\\u064A\": 'y',\n",
        "    ' ': ' ', \"\\u0621\": \"'\", \"\\u0623\": '>', \"\\u0625\": '<', \"\\u0624\": '&',\n",
        "    \"\\u0626\": '}', \"\\u0622\": '|', \"\\u064E\": 'a', \"\\u064F\": 'u', \"\\u0650\": 'i',\n",
        "    \"\\u0651\": '~', \"\\u0652\": 'o', \"\\u064B\": 'F', \"\\u064C\": 'N', \"\\u064D\": 'K',\n",
        "    \"\\u0640\": '_', \"\\u0670\": '`', \"\\u0629\": 'p'\n",
        "}\n",
        "\n",
        "alphabet = {v: k for k, v in abjad.items()}\n",
        "\n",
        "def buck_to_arabic(buc):\n",
        "    \"\"\"Convert Buckwalter to Arabic\"\"\"\n",
        "    try:\n",
        "        return ''.join(alphabet.get(x, x) for x in str(buc))\n",
        "    except:\n",
        "        return str(buc)\n",
        "\n",
        "def arabic_to_buck(ara):\n",
        "    \"\"\"Convert Arabic to Buckwalter\"\"\"\n",
        "    try:\n",
        "        return ''.join(abjad.get(x, x) for x in str(ara))\n",
        "    except:\n",
        "        return str(ara)\n",
        "\n",
        "print(\"üî§ Text conversion functions ready\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Semantic Metadata Layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define semantic categories for root classification\n",
        "semantic_categories = {\n",
        "    # Divine and Religious\n",
        "    'divine_attributes': ['ÿ±ÿ≠ŸÖ', 'ÿ∫ŸÅÿ±', 'ÿπŸÑŸÖ', 'ŸÇÿØÿ±', 'ÿ≠ŸÉŸÖ', 'ÿπÿ≤ÿ≤', 'ÿ≠ŸÖÿØ', 'ÿ≥ÿ®ÿ≠'],\n",
        "    'worship_ritual': ['ÿµŸÑŸà', 'ÿµŸàŸÖ', 'ÿ≠ÿ¨ÿ¨', 'ÿ≤ŸÉŸà', 'ÿ≥ÿ¨ÿØ', 'ÿ±ŸÉÿπ', 'ÿØÿπŸà', 'ÿ∞ŸÉÿ±'],\n",
        "    'faith_belief': ['ÿßŸÖŸÜ', 'ŸÉŸÅÿ±', 'ÿ¥ÿ±ŸÉ', 'Ÿàÿ≠ÿØ', 'ÿßŸäŸÖŸÜ', 'ŸäŸÇŸÜ', 'ÿ¥ŸÉŸÉ', 'ÿ∏ŸÜŸÜ'],\n",
        "    \n",
        "    # Human Relations and Society\n",
        "    'family_relations': ['ÿßÿ®Ÿà', 'ÿßŸÖŸÖ', 'ÿ≤Ÿàÿ¨', 'ŸàŸÑÿØ', 'ÿßÿÆŸà', 'ÿπÿ¥ÿ±', 'ŸÇÿ±ÿ®', 'ÿ±ÿ≠ŸÖ'],\n",
        "    'social_justice': ['ÿπÿØŸÑ', 'ÿ∏ŸÑŸÖ', 'ŸÇÿ≥ÿ∑', 'ÿ≠ŸÇŸÇ', 'ÿßŸÜÿµŸÅ', 'ŸÅÿ≥ÿØ', 'ÿµŸÑÿ≠'],\n",
        "    'commerce_economics': ['ÿ®Ÿäÿπ', 'ÿ¥ÿ±Ÿà', 'ÿ±ÿ®Ÿà', 'ÿØŸäŸÜ', 'ŸÇÿ±ÿ∂', 'ÿ™ÿ¨ÿ±', 'ŸÉÿ≥ÿ®', 'ÿßŸÜŸÅŸÇ'],\n",
        "    \n",
        "    # Knowledge and Communication\n",
        "    'knowledge_wisdom': ['ÿπŸÑŸÖ', 'ÿ≠ŸÉŸÖ', 'ŸÅŸáŸÖ', 'ÿπŸÇŸÑ', 'ŸÅŸÉÿ±', 'ÿ™ÿØÿ®ÿ±', 'ÿ∞ŸÉÿ±', 'ŸÅŸÇŸá'],\n",
        "    'communication': ['ŸÇŸàŸÑ', 'ŸÉŸÑŸÖ', 'ŸÜÿ∑ŸÇ', 'ÿµŸàÿ™', 'ŸÜÿØÿßÿ°', 'ÿ®ÿ¥ÿ±', 'ÿßŸÜÿ∞ÿ±', 'ÿ®ŸÑÿ∫'],\n",
        "    'books_revelation': ['ŸÉÿ™ÿ®', 'ŸÇÿ±ÿß', 'ŸÜÿ≤ŸÑ', 'Ÿàÿ≠Ÿä', 'ÿßŸäÿ™', 'ÿ™ŸÑŸà', 'ÿ≠ŸÅÿ∏'],\n",
        "    \n",
        "    # Natural World\n",
        "    'creation_nature': ['ÿÆŸÑŸÇ', 'ÿ®ÿ±ÿß', 'ŸÅÿ∑ÿ±', 'ÿßŸÜÿ¥ÿß', 'ÿ¨ÿπŸÑ', 'ŸÉŸàŸÜ', 'Ÿàÿ¨ÿØ'],\n",
        "    'time_temporal': ['ŸäŸàŸÖ', 'ŸÑŸäŸÑ', 'ÿµÿ®ÿ≠', 'ŸÖÿ≥ÿß', 'ŸàŸÇÿ™', 'ÿ≤ŸÖŸÜ', 'ÿØŸáÿ±', 'ÿπÿµÿ±'],\n",
        "    'natural_elements': ['ÿ≥ŸÖŸà', 'ÿßÿ±ÿ∂', 'ŸÖÿßÿ°', 'ŸÜÿßÿ±', 'ŸáŸàÿß', 'ÿ¥ŸÖÿ≥', 'ŸÇŸÖÿ±', 'ŸÜÿ¨ŸÖ'],\n",
        "    \n",
        "    # Actions and States\n",
        "    'movement_direction': ['ÿ∞Ÿáÿ®', 'ÿ¨Ÿäÿß', 'ÿ±ÿ¨ÿπ', 'ÿÆÿ±ÿ¨', 'ÿØÿÆŸÑ', 'ÿµÿπÿØ', 'ŸÜÿ≤ŸÑ', 'ÿ≥Ÿäÿ±'],\n",
        "    'emotions_states': ['ÿÆŸàŸÅ', 'ÿßŸÖŸÜ', 'ÿ≠ÿ≤ŸÜ', 'ŸÅÿ±ÿ≠', 'ÿ∫ÿ∂ÿ®', 'ÿ±ÿ∂Ÿà', 'ÿ≠ÿ®ÿ®', 'ÿ®ÿ∫ÿ∂'],\n",
        "    'moral_conduct': ['ÿµÿ®ÿ±', 'ÿ¥ŸÉÿ±', 'ÿ™ŸÇŸà', 'ÿ®ÿ±ÿ±', 'ŸÅÿ¨ÿ±', 'ŸÉÿ∞ÿ®', 'ÿµÿØŸÇ', 'ÿßŸÖŸÜ']\n",
        "}\n",
        "\n",
        "print(f\"üìã Defined {len(semantic_categories)} semantic categories\")\n",
        "print(f\"Total categorized roots: {sum(len(roots) for roots in semantic_categories.values())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create reverse mapping: root -> category\n",
        "root_to_category = {}\n",
        "for category, roots in semantic_categories.items():\n",
        "    for root in roots:\n",
        "        if root in root_to_category:\n",
        "            # Handle roots that might belong to multiple categories\n",
        "            if isinstance(root_to_category[root], list):\n",
        "                root_to_category[root].append(category)\n",
        "            else:\n",
        "                root_to_category[root] = [root_to_category[root], category]\n",
        "        else:\n",
        "            root_to_category[root] = category\n",
        "\n",
        "def get_semantic_category(root):\n",
        "    \"\"\"Get semantic category for a root\"\"\"\n",
        "    return root_to_category.get(root, 'uncategorized')\n",
        "\n",
        "# Test the function\n",
        "test_roots = ['ÿ±ÿ≠ŸÖ', 'ÿπŸÑŸÖ', 'ŸÉÿ™ÿ®']\n",
        "for root in test_roots:\n",
        "    category = get_semantic_category(root)\n",
        "    print(f\"Root {buck_to_arabic(root)} ({root}) -> {category}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Root categorization system ready\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Frequency Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate comprehensive frequency statistics\n",
        "print(\"üìä Calculating frequency analysis...\")\n",
        "\n",
        "# Overall root frequencies\n",
        "root_frequencies = quran[quran.Root.notna()].Root.value_counts()\n",
        "print(f\"Most frequent root: {buck_to_arabic(root_frequencies.index[0])} ({root_frequencies.iloc[0]} occurrences)\")\n",
        "\n",
        "# Frequency by revelation type\n",
        "meccan_freq = quran[(quran.Place == 'Meccan') & (quran.Root.notna())].Root.value_counts()\n",
        "medinan_freq = quran[(quran.Place == 'Medinan') & (quran.Root.notna())].Root.value_counts()\n",
        "\n",
        "print(f\"Meccan most frequent: {buck_to_arabic(meccan_freq.index[0])} ({meccan_freq.iloc[0]} occurrences)\")\n",
        "print(f\"Medinan most frequent: {buck_to_arabic(medinan_freq.index[0])} ({medinan_freq.iloc[0]} occurrences)\")\n",
        "\n",
        "# Frequency by sura\n",
        "sura_root_counts = quran[quran.Root.notna()].groupby('sura').Root.nunique().sort_values(ascending=False)\n",
        "print(f\"\\nSura with most unique roots: {sura_root_counts.index[0]} ({sura_root_counts.iloc[0]} unique roots)\")\n",
        "\n",
        "# Create frequency dataframe\n",
        "frequency_stats = pd.DataFrame({\n",
        "    'root': root_frequencies.index,\n",
        "    'total_frequency': root_frequencies.values,\n",
        "    'meccan_frequency': [meccan_freq.get(root, 0) for root in root_frequencies.index],\n",
        "    'medinan_frequency': [medinan_freq.get(root, 0) for root in root_frequencies.index]\n",
        "})\n",
        "\n",
        "# Add relative frequencies\n",
        "frequency_stats['meccan_ratio'] = frequency_stats['meccan_frequency'] / frequency_stats['total_frequency']\n",
        "frequency_stats['medinan_ratio'] = frequency_stats['medinan_frequency'] / frequency_stats['total_frequency']\n",
        "\n",
        "# Add semantic categories\n",
        "frequency_stats['semantic_category'] = frequency_stats['root'].apply(get_semantic_category)\n",
        "\n",
        "# Add Arabic forms\n",
        "frequency_stats['root_arabic'] = frequency_stats['root'].apply(buck_to_arabic)\n",
        "\n",
        "print(f\"\\n‚úÖ Frequency analysis complete for {len(frequency_stats)} roots\")\n",
        "frequency_stats.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Advanced frequency analysis\n",
        "print(\"üîç Advanced frequency patterns...\")\n",
        "\n",
        "# Roots with strong Meccan preference (>80% Meccan)\n",
        "meccan_preferred = frequency_stats[\n",
        "    (frequency_stats['meccan_ratio'] > 0.8) & \n",
        "    (frequency_stats['total_frequency'] >= 5)  # At least 5 occurrences\n",
        "].sort_values('meccan_ratio', ascending=False)\n",
        "\n",
        "print(f\"\\nüïå Strongly Meccan-preferred roots (>80%, ‚â•5 occurrences): {len(meccan_preferred)}\")\n",
        "print(\"Top 10:\")\n",
        "for _, row in meccan_preferred.head(10).iterrows():\n",
        "    print(f\"  {row['root_arabic']:>8} ({row['root']:>6}) - {row['meccan_ratio']:.1%} Meccan ({row['total_frequency']} total)\")\n",
        "\n",
        "# Roots with strong Medinan preference (>80% Medinan)\n",
        "medinan_preferred = frequency_stats[\n",
        "    (frequency_stats['medinan_ratio'] > 0.8) & \n",
        "    (frequency_stats['total_frequency'] >= 5)\n",
        "].sort_values('medinan_ratio', ascending=False)\n",
        "\n",
        "print(f\"\\nüèõÔ∏è Strongly Medinan-preferred roots (>80%, ‚â•5 occurrences): {len(medinan_preferred)}\")\n",
        "print(\"Top 10:\")\n",
        "for _, row in medinan_preferred.head(10).iterrows():\n",
        "    print(f\"  {row['root_arabic']:>8} ({row['root']:>6}) - {row['medinan_ratio']:.1%} Medinan ({row['total_frequency']} total)\")\n",
        "\n",
        "# Rare roots (appear only 1-2 times)\n",
        "rare_roots = frequency_stats[frequency_stats['total_frequency'] <= 2]\n",
        "print(f\"\\nüîπ Rare roots (‚â§2 occurrences): {len(rare_roots)} ({len(rare_roots)/len(frequency_stats):.1%} of all roots)\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Thematic Categorization Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze frequency patterns by semantic category\n",
        "print(\"üéØ Thematic categorization analysis...\")\n",
        "\n",
        "# Category frequency distribution\n",
        "category_stats = frequency_stats.groupby('semantic_category').agg({\n",
        "    'total_frequency': ['count', 'sum', 'mean'],\n",
        "    'meccan_frequency': 'sum',\n",
        "    'medinan_frequency': 'sum'\n",
        "}).round(2)\n",
        "\n",
        "category_stats.columns = ['root_count', 'total_occurrences', 'avg_frequency', 'meccan_total', 'medinan_total']\n",
        "category_stats['meccan_ratio'] = category_stats['meccan_total'] / (category_stats['meccan_total'] + category_stats['medinan_total'])\n",
        "category_stats = category_stats.sort_values('total_occurrences', ascending=False)\n",
        "\n",
        "print(\"\\nüìä Semantic category statistics:\")\n",
        "print(category_stats)\n",
        "\n",
        "# Find categories with strong revelation type preferences\n",
        "print(\"\\nüé≠ Categories with revelation preferences:\")\n",
        "for category, row in category_stats.iterrows():\n",
        "    if row['meccan_ratio'] > 0.7:\n",
        "        print(f\"  üïå {category}: {row['meccan_ratio']:.1%} Meccan\")\n",
        "    elif row['meccan_ratio'] < 0.3:\n",
        "        print(f\"  üèõÔ∏è {category}: {1-row['meccan_ratio']:.1%} Medinan\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create thematic distribution by sura\n",
        "print(\"üìö Thematic distribution by sura...\")\n",
        "\n",
        "# Add semantic categories to main dataset\n",
        "quran_enhanced = quran.copy()\n",
        "quran_enhanced['semantic_category'] = quran_enhanced['Root'].apply(get_semantic_category)\n",
        "\n",
        "# Calculate category distribution by sura\n",
        "sura_theme_distribution = quran_enhanced[quran_enhanced.Root.notna()].groupby(['sura', 'semantic_category']).size().unstack(fill_value=0)\n",
        "\n",
        "# Calculate relative distributions\n",
        "sura_theme_relative = sura_theme_distribution.div(sura_theme_distribution.sum(axis=1), axis=0)\n",
        "\n",
        "print(f\"‚úÖ Thematic analysis complete for {len(sura_theme_distribution)} suras\")\n",
        "print(f\"Categories tracked: {list(sura_theme_distribution.columns)}\")\n",
        "\n",
        "# Show example for Al-Fatiha\n",
        "print(\"\\nüìñ Example - Al-Fatiha (Sura 1) thematic breakdown:\")\n",
        "if 1 in sura_theme_relative.index:\n",
        "    fatiha_themes = sura_theme_relative.loc[1]\n",
        "    for theme, ratio in fatiha_themes[fatiha_themes > 0].sort_values(ascending=False).items():\n",
        "        print(f\"  {theme}: {ratio:.1%}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Co-occurrence Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate root co-occurrences within verses\n",
        "print(\"üîó Calculating root co-occurrence matrices...\")\n",
        "\n",
        "# Group by verse to find roots that appear together\n",
        "verse_roots = quran_enhanced[quran_enhanced.Root.notna()].groupby(['sura', 'aya'])['Root'].apply(list).reset_index()\n",
        "verse_roots['root_count'] = verse_roots['Root'].apply(len)\n",
        "\n",
        "print(f\"Analyzed {len(verse_roots)} verses with roots\")\n",
        "print(f\"Average roots per verse: {verse_roots['root_count'].mean():.1f}\")\n",
        "print(f\"Max roots in a verse: {verse_roots['root_count'].max()}\")\n",
        "\n",
        "# Calculate co-occurrence matrix\n",
        "cooccurrence_counts = defaultdict(int)\n",
        "total_pairs = 0\n",
        "\n",
        "for _, row in verse_roots.iterrows():\n",
        "    roots_in_verse = list(set(row['Root']))  # Remove duplicates within verse\n",
        "    if len(roots_in_verse) > 1:\n",
        "        for root1, root2 in combinations(roots_in_verse, 2):\n",
        "            # Sort pair to ensure consistent ordering\n",
        "            pair = tuple(sorted([root1, root2]))\n",
        "            cooccurrence_counts[pair] += 1\n",
        "            total_pairs += 1\n",
        "\n",
        "print(f\"\\nüî¢ Found {len(cooccurrence_counts)} unique root pairs\")\n",
        "print(f\"Total co-occurrence instances: {total_pairs}\")\n",
        "\n",
        "# Convert to DataFrame for analysis\n",
        "cooccurrence_df = pd.DataFrame([\n",
        "    {'root1': pair[0], 'root2': pair[1], 'cooccurrence_count': count}\n",
        "    for pair, count in cooccurrence_counts.items()\n",
        "]).sort_values('cooccurrence_count', ascending=False)\n",
        "\n",
        "print(\"\\nüîù Top 10 most co-occurring root pairs:\")\n",
        "for _, row in cooccurrence_df.head(10).iterrows():\n",
        "    r1_ar = buck_to_arabic(row['root1'])\n",
        "    r2_ar = buck_to_arabic(row['root2'])\n",
        "    print(f\"  {r1_ar} + {r2_ar}: {row['cooccurrence_count']} times\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate semantic co-occurrence patterns\n",
        "print(\"üé≠ Semantic category co-occurrence analysis...\")\n",
        "\n",
        "# Add semantic categories to co-occurrence data\n",
        "cooccurrence_df['category1'] = cooccurrence_df['root1'].apply(get_semantic_category)\n",
        "cooccurrence_df['category2'] = cooccurrence_df['root2'].apply(get_semantic_category)\n",
        "\n",
        "# Calculate category-level co-occurrences\n",
        "category_cooccurrence = defaultdict(int)\n",
        "for _, row in cooccurrence_df.iterrows():\n",
        "    cat_pair = tuple(sorted([row['category1'], row['category2']]))\n",
        "    category_cooccurrence[cat_pair] += row['cooccurrence_count']\n",
        "\n",
        "category_cooccurrence_df = pd.DataFrame([\n",
        "    {'category1': pair[0], 'category2': pair[1], 'total_cooccurrence': count}\n",
        "    for pair, count in category_cooccurrence.items()\n",
        "    if pair[0] != 'uncategorized' and pair[1] != 'uncategorized'  # Filter out uncategorized\n",
        "]).sort_values('total_cooccurrence', ascending=False)\n",
        "\n",
        "print(\"\\nüéØ Top semantic category co-occurrences:\")\n",
        "for _, row in category_cooccurrence_df.head(15).iterrows():\n",
        "    if row['category1'] != row['category2']:  # Different categories\n",
        "        print(f\"  {row['category1']} + {row['category2']}: {row['total_cooccurrence']} co-occurrences\")\n",
        "    else:  # Same category (internal consistency)\n",
        "        print(f\"  {row['category1']} (internal): {row['total_cooccurrence']} co-occurrences\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Enhanced Dataset Creation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive enhanced dataset\n",
        "print(\"üíé Creating enhanced dataset with all metadata...\")\n",
        "\n",
        "# Merge frequency statistics with root data\n",
        "frequency_lookup = frequency_stats.set_index('root').to_dict('index')\n",
        "\n",
        "def add_frequency_info(root):\n",
        "    if pd.isna(root) or root not in frequency_lookup:\n",
        "        return {'total_freq': 0, 'meccan_freq': 0, 'medinan_freq': 0, 'meccan_ratio': 0, 'frequency_rank': 0}\n",
        "    info = frequency_lookup[root]\n",
        "    return {\n",
        "        'total_freq': info['total_frequency'],\n",
        "        'meccan_freq': info['meccan_frequency'], \n",
        "        'medinan_freq': info['medinan_frequency'],\n",
        "        'meccan_ratio': info['meccan_ratio'],\n",
        "        'frequency_rank': frequency_stats[frequency_stats['root'] == root].index[0] + 1\n",
        "    }\n",
        "\n",
        "# Add all enhancements to the dataset\n",
        "enhanced_quran = quran_enhanced.copy()\n",
        "\n",
        "# Add frequency information\n",
        "freq_info = enhanced_quran['Root'].apply(add_frequency_info)\n",
        "for key in ['total_freq', 'meccan_freq', 'medinan_freq', 'meccan_ratio', 'frequency_rank']:\n",
        "    enhanced_quran[f'root_{key}'] = [info[key] for info in freq_info]\n",
        "\n",
        "# Add Arabic root form\n",
        "enhanced_quran['root_arabic'] = enhanced_quran['Root'].apply(lambda x: buck_to_arabic(x) if pd.notna(x) else '')\n",
        "\n",
        "# Add rarity classification\n",
        "def classify_rarity(freq):\n",
        "    if freq == 0: return 'no_root'\n",
        "    elif freq == 1: return 'hapax_legomena'\n",
        "    elif freq <= 5: return 'very_rare'\n",
        "    elif freq <= 20: return 'rare'\n",
        "    elif freq <= 100: return 'common'\n",
        "    else: return 'very_common'\n",
        "\n",
        "enhanced_quran['root_rarity'] = enhanced_quran['root_total_freq'].apply(classify_rarity)\n",
        "\n",
        "# Add revelation preference classification\n",
        "def classify_revelation_preference(ratio, total_freq):\n",
        "    if total_freq < 3: return 'insufficient_data'\n",
        "    elif ratio > 0.8: return 'strongly_meccan'\n",
        "    elif ratio > 0.6: return 'meccan_leaning'\n",
        "    elif ratio < 0.2: return 'strongly_medinan'\n",
        "    elif ratio < 0.4: return 'medinan_leaning'\n",
        "    else: return 'balanced'\n",
        "\n",
        "enhanced_quran['revelation_preference'] = enhanced_quran.apply(\n",
        "    lambda row: classify_revelation_preference(row['root_meccan_ratio'], row['root_total_freq']), axis=1\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Enhanced dataset created with {len(enhanced_quran)} entries\")\n",
        "print(f\"New columns added: {[col for col in enhanced_quran.columns if col not in quran.columns]}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. Data Export and Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save enhanced datasets\n",
        "print(\"üíæ Saving enhanced datasets...\")\n",
        "\n",
        "# Main enhanced dataset\n",
        "enhanced_quran.to_csv('quran-enhanced-phase1.csv', index=False)\n",
        "print(f\"‚úÖ Saved main enhanced dataset: quran-enhanced-phase1.csv\")\n",
        "\n",
        "# Frequency statistics\n",
        "frequency_stats.to_csv('root-frequency-analysis.csv', index=False)\n",
        "print(f\"‚úÖ Saved frequency analysis: root-frequency-analysis.csv\")\n",
        "\n",
        "# Semantic category analysis\n",
        "category_stats.to_csv('semantic-category-analysis.csv')\n",
        "print(f\"‚úÖ Saved category analysis: semantic-category-analysis.csv\")\n",
        "\n",
        "# Co-occurrence matrices\n",
        "cooccurrence_df.to_csv('root-cooccurrence-matrix.csv', index=False)\n",
        "category_cooccurrence_df.to_csv('category-cooccurrence-matrix.csv', index=False)\n",
        "print(f\"‚úÖ Saved co-occurrence matrices\")\n",
        "\n",
        "# Thematic distribution by sura\n",
        "sura_theme_distribution.to_csv('sura-thematic-distribution.csv')\n",
        "sura_theme_relative.to_csv('sura-thematic-relative.csv')\n",
        "print(f\"‚úÖ Saved thematic distributions\")\n",
        "\n",
        "# Create metadata summary\n",
        "metadata_summary = {\n",
        "    'dataset_info': {\n",
        "        'total_entries': len(enhanced_quran),\n",
        "        'entries_with_roots': enhanced_quran['Root'].notna().sum(),\n",
        "        'unique_roots': enhanced_quran['Root'].nunique(),\n",
        "        'enhancement_date': pd.Timestamp.now().isoformat()\n",
        "    },\n",
        "    'semantic_categories': list(semantic_categories.keys()),\n",
        "    'frequency_statistics': {\n",
        "        'most_frequent_root': frequency_stats.iloc[0]['root'],\n",
        "        'most_frequent_count': int(frequency_stats.iloc[0]['total_frequency']),\n",
        "        'hapax_legomena_count': len(frequency_stats[frequency_stats['total_frequency'] == 1]),\n",
        "        'rare_roots_count': len(frequency_stats[frequency_stats['total_frequency'] <= 5])\n",
        "    },\n",
        "    'co_occurrence_stats': {\n",
        "        'unique_pairs': len(cooccurrence_df),\n",
        "        'total_co_occurrences': total_pairs,\n",
        "        'top_pair': (cooccurrence_df.iloc[0]['root1'], cooccurrence_df.iloc[0]['root2']),\n",
        "        'top_pair_count': int(cooccurrence_df.iloc[0]['cooccurrence_count'])\n",
        "    }\n",
        "}\n",
        "\n",
        "with open('enhancement-metadata.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(metadata_summary, f, indent=2, ensure_ascii=False)\n",
        "print(f\"‚úÖ Saved metadata summary: enhancement-metadata.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final comprehensive summary\n",
        "print(\"üìã PHASE 1 ENHANCEMENT SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(f\"\\nüìä Dataset Enhancements:\")\n",
        "print(f\"  Original entries: {len(quran):,}\")\n",
        "print(f\"  Enhanced entries: {len(enhanced_quran):,}\")\n",
        "print(f\"  New metadata columns: {len(enhanced_quran.columns) - len(quran.columns)}\")\n",
        "\n",
        "print(f\"\\nüéØ Semantic Analysis:\")\n",
        "print(f\"  Categories defined: {len(semantic_categories)}\")\n",
        "print(f\"  Roots categorized: {sum(len(roots) for roots in semantic_categories.values())}\")\n",
        "print(f\"  Category coverage: {(enhanced_quran['semantic_category'] != 'uncategorized').sum() / len(enhanced_quran) * 100:.1f}%\")\n",
        "\n",
        "print(f\"\\nüìà Frequency Analysis:\")\n",
        "print(f\"  Unique roots analyzed: {len(frequency_stats)}\")\n",
        "print(f\"  Hapax legomena: {len(frequency_stats[frequency_stats['total_frequency'] == 1])}\")\n",
        "print(f\"  Strongly Meccan roots: {len(meccan_preferred)}\")\n",
        "print(f\"  Strongly Medinan roots: {len(medinan_preferred)}\")\n",
        "\n",
        "print(f\"\\nüîó Co-occurrence Analysis:\")\n",
        "print(f\"  Verses analyzed: {len(verse_roots)}\")\n",
        "print(f\"  Root pairs found: {len(cooccurrence_df)}\")\n",
        "print(f\"  Category pairs: {len(category_cooccurrence_df)}\")\n",
        "\n",
        "print(f\"\\nüíæ Files Created:\")\n",
        "files_created = [\n",
        "    'quran-enhanced-phase1.csv',\n",
        "    'root-frequency-analysis.csv', \n",
        "    'semantic-category-analysis.csv',\n",
        "    'root-cooccurrence-matrix.csv',\n",
        "    'category-cooccurrence-matrix.csv',\n",
        "    'sura-thematic-distribution.csv',\n",
        "    'sura-thematic-relative.csv',\n",
        "    'enhancement-metadata.json'\n",
        "]\n",
        "for file in files_created:\n",
        "    print(f\"  ‚úÖ {file}\")\n",
        "\n",
        "print(f\"\\nüöÄ Ready for Phase 2: Backend API Development\")\n",
        "print(f\"\\n‚ú® Phase 1 Enhancement Complete! ‚ú®\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
