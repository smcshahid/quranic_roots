{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Enhanced Quranic Root Words Analysis - Phase 1\n",
        "\n",
        "This notebook enhances the basic morphological analysis with:\n",
        "- **Semantic Metadata Layer**: Meaning categories and themes\n",
        "- **Frequency Analysis**: Statistical patterns and distributions\n",
        "- **Thematic Categorization**: Subject-based root groupings\n",
        "- **Co-occurrence Matrices**: Root relationship networks\n",
        "\n",
        "Building upon the foundation from `quran_corrected.ipynb`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enhanced imports for advanced analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter, defaultdict\n",
        "import networkx as nx\n",
        "from itertools import combinations\n",
        "import json\n",
        "from functools import lru_cache\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"📚 Enhanced libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Load and Prepare Base Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the processed data from previous analysis\n",
        "print(\"📥 Loading processed Quranic data...\")\n",
        "try:\n",
        "    quran = pd.read_csv('quran-morphology-final.csv')\n",
        "    print(f\"✅ Loaded {len(quran):,} entries\")\n",
        "except FileNotFoundError:\n",
        "    print(\"❌ Base data file not found. Please run quran_corrected.ipynb first.\")\n",
        "    raise\n",
        "\n",
        "# Load table of contents\n",
        "toc = pd.read_csv('toc.csv')\n",
        "print(f\"✅ Loaded TOC with {len(toc)} suras\")\n",
        "\n",
        "# Display basic info\n",
        "print(f\"\\n📊 Dataset Overview:\")\n",
        "print(f\"Total entries: {len(quran):,}\")\n",
        "print(f\"Entries with roots: {quran.Root.notna().sum():,}\")\n",
        "print(f\"Unique roots: {quran.Root.nunique():,}\")\n",
        "print(f\"Meccan suras: {len(toc[toc.Place == 'Meccan'])}\")\n",
        "print(f\"Medinan suras: {len(toc[toc.Place == 'Medinan'])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up Buckwalter conversion functions (from previous notebook)\n",
        "abjad = {\n",
        "    \"\\u0627\": 'A', \"\\u0628\": 'b', \"\\u062A\": 't', \"\\u062B\": 'v', \"\\u062C\": 'j',\n",
        "    \"\\u062D\": 'H', \"\\u062E\": 'x', \"\\u062F\": 'd', \"\\u0630\": '*', \"\\u0631\": 'r',\n",
        "    \"\\u0632\": 'z', \"\\u0633\": 's', \"\\u0634\": '$', \"\\u0635\": 'S', \"\\u0636\": 'D',\n",
        "    \"\\u0637\": 'T', \"\\u0638\": 'Z', \"\\u0639\": 'E', \"\\u063A\": 'g', \"\\u0641\": 'f',\n",
        "    \"\\u0642\": 'q', \"\\u0643\": 'k', \"\\u0644\": 'l', \"\\u0645\": 'm', \"\\u0646\": 'n',\n",
        "    \"\\u0647\": 'h', \"\\u0648\": 'w', \"\\u0649\": 'Y', \"\\u064A\": 'y',\n",
        "    ' ': ' ', \"\\u0621\": \"'\", \"\\u0623\": '>', \"\\u0625\": '<', \"\\u0624\": '&',\n",
        "    \"\\u0626\": '}', \"\\u0622\": '|', \"\\u064E\": 'a', \"\\u064F\": 'u', \"\\u0650\": 'i',\n",
        "    \"\\u0651\": '~', \"\\u0652\": 'o', \"\\u064B\": 'F', \"\\u064C\": 'N', \"\\u064D\": 'K',\n",
        "    \"\\u0640\": '_', \"\\u0670\": '`', \"\\u0629\": 'p'\n",
        "}\n",
        "\n",
        "alphabet = {v: k for k, v in abjad.items()}\n",
        "\n",
        "def buck_to_arabic(buc):\n",
        "    \"\"\"Convert Buckwalter to Arabic\"\"\"\n",
        "    try:\n",
        "        return ''.join(alphabet.get(x, x) for x in str(buc))\n",
        "    except:\n",
        "        return str(buc)\n",
        "\n",
        "def arabic_to_buck(ara):\n",
        "    \"\"\"Convert Arabic to Buckwalter\"\"\"\n",
        "    try:\n",
        "        return ''.join(abjad.get(x, x) for x in str(ara))\n",
        "    except:\n",
        "        return str(ara)\n",
        "\n",
        "print(\"🔤 Text conversion functions ready\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Semantic Metadata Layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define semantic categories for root classification\n",
        "semantic_categories = {\n",
        "    # Divine and Religious\n",
        "    'divine_attributes': ['رحم', 'غفر', 'علم', 'قدر', 'حكم', 'عزز', 'حمد', 'سبح'],\n",
        "    'worship_ritual': ['صلو', 'صوم', 'حجج', 'زكو', 'سجد', 'ركع', 'دعو', 'ذكر'],\n",
        "    'faith_belief': ['امن', 'كفر', 'شرك', 'وحد', 'ايمن', 'يقن', 'شكك', 'ظنن'],\n",
        "    \n",
        "    # Human Relations and Society\n",
        "    'family_relations': ['ابو', 'امم', 'زوج', 'ولد', 'اخو', 'عشر', 'قرب', 'رحم'],\n",
        "    'social_justice': ['عدل', 'ظلم', 'قسط', 'حقق', 'انصف', 'فسد', 'صلح'],\n",
        "    'commerce_economics': ['بيع', 'شرو', 'ربو', 'دين', 'قرض', 'تجر', 'كسب', 'انفق'],\n",
        "    \n",
        "    # Knowledge and Communication\n",
        "    'knowledge_wisdom': ['علم', 'حكم', 'فهم', 'عقل', 'فكر', 'تدبر', 'ذكر', 'فقه'],\n",
        "    'communication': ['قول', 'كلم', 'نطق', 'صوت', 'نداء', 'بشر', 'انذر', 'بلغ'],\n",
        "    'books_revelation': ['كتب', 'قرا', 'نزل', 'وحي', 'ايت', 'تلو', 'حفظ'],\n",
        "    \n",
        "    # Natural World\n",
        "    'creation_nature': ['خلق', 'برا', 'فطر', 'انشا', 'جعل', 'كون', 'وجد'],\n",
        "    'time_temporal': ['يوم', 'ليل', 'صبح', 'مسا', 'وقت', 'زمن', 'دهر', 'عصر'],\n",
        "    'natural_elements': ['سمو', 'ارض', 'ماء', 'نار', 'هوا', 'شمس', 'قمر', 'نجم'],\n",
        "    \n",
        "    # Actions and States\n",
        "    'movement_direction': ['ذهب', 'جيا', 'رجع', 'خرج', 'دخل', 'صعد', 'نزل', 'سير'],\n",
        "    'emotions_states': ['خوف', 'امن', 'حزن', 'فرح', 'غضب', 'رضو', 'حبب', 'بغض'],\n",
        "    'moral_conduct': ['صبر', 'شكر', 'تقو', 'برر', 'فجر', 'كذب', 'صدق', 'امن']\n",
        "}\n",
        "\n",
        "print(f\"📋 Defined {len(semantic_categories)} semantic categories\")\n",
        "print(f\"Total categorized roots: {sum(len(roots) for roots in semantic_categories.values())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create reverse mapping: root -> category\n",
        "root_to_category = {}\n",
        "for category, roots in semantic_categories.items():\n",
        "    for root in roots:\n",
        "        if root in root_to_category:\n",
        "            # Handle roots that might belong to multiple categories\n",
        "            if isinstance(root_to_category[root], list):\n",
        "                root_to_category[root].append(category)\n",
        "            else:\n",
        "                root_to_category[root] = [root_to_category[root], category]\n",
        "        else:\n",
        "            root_to_category[root] = category\n",
        "\n",
        "def get_semantic_category(root):\n",
        "    \"\"\"Get semantic category for a root\"\"\"\n",
        "    return root_to_category.get(root, 'uncategorized')\n",
        "\n",
        "# Test the function\n",
        "test_roots = ['رحم', 'علم', 'كتب']\n",
        "for root in test_roots:\n",
        "    category = get_semantic_category(root)\n",
        "    print(f\"Root {buck_to_arabic(root)} ({root}) -> {category}\")\n",
        "\n",
        "print(f\"\\n✅ Root categorization system ready\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Frequency Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate comprehensive frequency statistics\n",
        "print(\"📊 Calculating frequency analysis...\")\n",
        "\n",
        "# Overall root frequencies\n",
        "root_frequencies = quran[quran.Root.notna()].Root.value_counts()\n",
        "print(f\"Most frequent root: {buck_to_arabic(root_frequencies.index[0])} ({root_frequencies.iloc[0]} occurrences)\")\n",
        "\n",
        "# Frequency by revelation type\n",
        "meccan_freq = quran[(quran.Place == 'Meccan') & (quran.Root.notna())].Root.value_counts()\n",
        "medinan_freq = quran[(quran.Place == 'Medinan') & (quran.Root.notna())].Root.value_counts()\n",
        "\n",
        "print(f\"Meccan most frequent: {buck_to_arabic(meccan_freq.index[0])} ({meccan_freq.iloc[0]} occurrences)\")\n",
        "print(f\"Medinan most frequent: {buck_to_arabic(medinan_freq.index[0])} ({medinan_freq.iloc[0]} occurrences)\")\n",
        "\n",
        "# Frequency by sura\n",
        "sura_root_counts = quran[quran.Root.notna()].groupby('sura').Root.nunique().sort_values(ascending=False)\n",
        "print(f\"\\nSura with most unique roots: {sura_root_counts.index[0]} ({sura_root_counts.iloc[0]} unique roots)\")\n",
        "\n",
        "# Create frequency dataframe\n",
        "frequency_stats = pd.DataFrame({\n",
        "    'root': root_frequencies.index,\n",
        "    'total_frequency': root_frequencies.values,\n",
        "    'meccan_frequency': [meccan_freq.get(root, 0) for root in root_frequencies.index],\n",
        "    'medinan_frequency': [medinan_freq.get(root, 0) for root in root_frequencies.index]\n",
        "})\n",
        "\n",
        "# Add relative frequencies\n",
        "frequency_stats['meccan_ratio'] = frequency_stats['meccan_frequency'] / frequency_stats['total_frequency']\n",
        "frequency_stats['medinan_ratio'] = frequency_stats['medinan_frequency'] / frequency_stats['total_frequency']\n",
        "\n",
        "# Add semantic categories\n",
        "frequency_stats['semantic_category'] = frequency_stats['root'].apply(get_semantic_category)\n",
        "\n",
        "# Add Arabic forms\n",
        "frequency_stats['root_arabic'] = frequency_stats['root'].apply(buck_to_arabic)\n",
        "\n",
        "print(f\"\\n✅ Frequency analysis complete for {len(frequency_stats)} roots\")\n",
        "frequency_stats.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Advanced frequency analysis\n",
        "print(\"🔍 Advanced frequency patterns...\")\n",
        "\n",
        "# Roots with strong Meccan preference (>80% Meccan)\n",
        "meccan_preferred = frequency_stats[\n",
        "    (frequency_stats['meccan_ratio'] > 0.8) & \n",
        "    (frequency_stats['total_frequency'] >= 5)  # At least 5 occurrences\n",
        "].sort_values('meccan_ratio', ascending=False)\n",
        "\n",
        "print(f\"\\n🕌 Strongly Meccan-preferred roots (>80%, ≥5 occurrences): {len(meccan_preferred)}\")\n",
        "print(\"Top 10:\")\n",
        "for _, row in meccan_preferred.head(10).iterrows():\n",
        "    print(f\"  {row['root_arabic']:>8} ({row['root']:>6}) - {row['meccan_ratio']:.1%} Meccan ({row['total_frequency']} total)\")\n",
        "\n",
        "# Roots with strong Medinan preference (>80% Medinan)\n",
        "medinan_preferred = frequency_stats[\n",
        "    (frequency_stats['medinan_ratio'] > 0.8) & \n",
        "    (frequency_stats['total_frequency'] >= 5)\n",
        "].sort_values('medinan_ratio', ascending=False)\n",
        "\n",
        "print(f\"\\n🏛️ Strongly Medinan-preferred roots (>80%, ≥5 occurrences): {len(medinan_preferred)}\")\n",
        "print(\"Top 10:\")\n",
        "for _, row in medinan_preferred.head(10).iterrows():\n",
        "    print(f\"  {row['root_arabic']:>8} ({row['root']:>6}) - {row['medinan_ratio']:.1%} Medinan ({row['total_frequency']} total)\")\n",
        "\n",
        "# Rare roots (appear only 1-2 times)\n",
        "rare_roots = frequency_stats[frequency_stats['total_frequency'] <= 2]\n",
        "print(f\"\\n🔹 Rare roots (≤2 occurrences): {len(rare_roots)} ({len(rare_roots)/len(frequency_stats):.1%} of all roots)\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Thematic Categorization Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze frequency patterns by semantic category\n",
        "print(\"🎯 Thematic categorization analysis...\")\n",
        "\n",
        "# Category frequency distribution\n",
        "category_stats = frequency_stats.groupby('semantic_category').agg({\n",
        "    'total_frequency': ['count', 'sum', 'mean'],\n",
        "    'meccan_frequency': 'sum',\n",
        "    'medinan_frequency': 'sum'\n",
        "}).round(2)\n",
        "\n",
        "category_stats.columns = ['root_count', 'total_occurrences', 'avg_frequency', 'meccan_total', 'medinan_total']\n",
        "category_stats['meccan_ratio'] = category_stats['meccan_total'] / (category_stats['meccan_total'] + category_stats['medinan_total'])\n",
        "category_stats = category_stats.sort_values('total_occurrences', ascending=False)\n",
        "\n",
        "print(\"\\n📊 Semantic category statistics:\")\n",
        "print(category_stats)\n",
        "\n",
        "# Find categories with strong revelation type preferences\n",
        "print(\"\\n🎭 Categories with revelation preferences:\")\n",
        "for category, row in category_stats.iterrows():\n",
        "    if row['meccan_ratio'] > 0.7:\n",
        "        print(f\"  🕌 {category}: {row['meccan_ratio']:.1%} Meccan\")\n",
        "    elif row['meccan_ratio'] < 0.3:\n",
        "        print(f\"  🏛️ {category}: {1-row['meccan_ratio']:.1%} Medinan\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create thematic distribution by sura\n",
        "print(\"📚 Thematic distribution by sura...\")\n",
        "\n",
        "# Add semantic categories to main dataset\n",
        "quran_enhanced = quran.copy()\n",
        "quran_enhanced['semantic_category'] = quran_enhanced['Root'].apply(get_semantic_category)\n",
        "\n",
        "# Calculate category distribution by sura\n",
        "sura_theme_distribution = quran_enhanced[quran_enhanced.Root.notna()].groupby(['sura', 'semantic_category']).size().unstack(fill_value=0)\n",
        "\n",
        "# Calculate relative distributions\n",
        "sura_theme_relative = sura_theme_distribution.div(sura_theme_distribution.sum(axis=1), axis=0)\n",
        "\n",
        "print(f\"✅ Thematic analysis complete for {len(sura_theme_distribution)} suras\")\n",
        "print(f\"Categories tracked: {list(sura_theme_distribution.columns)}\")\n",
        "\n",
        "# Show example for Al-Fatiha\n",
        "print(\"\\n📖 Example - Al-Fatiha (Sura 1) thematic breakdown:\")\n",
        "if 1 in sura_theme_relative.index:\n",
        "    fatiha_themes = sura_theme_relative.loc[1]\n",
        "    for theme, ratio in fatiha_themes[fatiha_themes > 0].sort_values(ascending=False).items():\n",
        "        print(f\"  {theme}: {ratio:.1%}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Co-occurrence Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate root co-occurrences within verses\n",
        "print(\"🔗 Calculating root co-occurrence matrices...\")\n",
        "\n",
        "# Group by verse to find roots that appear together\n",
        "verse_roots = quran_enhanced[quran_enhanced.Root.notna()].groupby(['sura', 'aya'])['Root'].apply(list).reset_index()\n",
        "verse_roots['root_count'] = verse_roots['Root'].apply(len)\n",
        "\n",
        "print(f\"Analyzed {len(verse_roots)} verses with roots\")\n",
        "print(f\"Average roots per verse: {verse_roots['root_count'].mean():.1f}\")\n",
        "print(f\"Max roots in a verse: {verse_roots['root_count'].max()}\")\n",
        "\n",
        "# Calculate co-occurrence matrix\n",
        "cooccurrence_counts = defaultdict(int)\n",
        "total_pairs = 0\n",
        "\n",
        "for _, row in verse_roots.iterrows():\n",
        "    roots_in_verse = list(set(row['Root']))  # Remove duplicates within verse\n",
        "    if len(roots_in_verse) > 1:\n",
        "        for root1, root2 in combinations(roots_in_verse, 2):\n",
        "            # Sort pair to ensure consistent ordering\n",
        "            pair = tuple(sorted([root1, root2]))\n",
        "            cooccurrence_counts[pair] += 1\n",
        "            total_pairs += 1\n",
        "\n",
        "print(f\"\\n🔢 Found {len(cooccurrence_counts)} unique root pairs\")\n",
        "print(f\"Total co-occurrence instances: {total_pairs}\")\n",
        "\n",
        "# Convert to DataFrame for analysis\n",
        "cooccurrence_df = pd.DataFrame([\n",
        "    {'root1': pair[0], 'root2': pair[1], 'cooccurrence_count': count}\n",
        "    for pair, count in cooccurrence_counts.items()\n",
        "]).sort_values('cooccurrence_count', ascending=False)\n",
        "\n",
        "print(\"\\n🔝 Top 10 most co-occurring root pairs:\")\n",
        "for _, row in cooccurrence_df.head(10).iterrows():\n",
        "    r1_ar = buck_to_arabic(row['root1'])\n",
        "    r2_ar = buck_to_arabic(row['root2'])\n",
        "    print(f\"  {r1_ar} + {r2_ar}: {row['cooccurrence_count']} times\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate semantic co-occurrence patterns\n",
        "print(\"🎭 Semantic category co-occurrence analysis...\")\n",
        "\n",
        "# Add semantic categories to co-occurrence data\n",
        "cooccurrence_df['category1'] = cooccurrence_df['root1'].apply(get_semantic_category)\n",
        "cooccurrence_df['category2'] = cooccurrence_df['root2'].apply(get_semantic_category)\n",
        "\n",
        "# Calculate category-level co-occurrences\n",
        "category_cooccurrence = defaultdict(int)\n",
        "for _, row in cooccurrence_df.iterrows():\n",
        "    cat_pair = tuple(sorted([row['category1'], row['category2']]))\n",
        "    category_cooccurrence[cat_pair] += row['cooccurrence_count']\n",
        "\n",
        "category_cooccurrence_df = pd.DataFrame([\n",
        "    {'category1': pair[0], 'category2': pair[1], 'total_cooccurrence': count}\n",
        "    for pair, count in category_cooccurrence.items()\n",
        "    if pair[0] != 'uncategorized' and pair[1] != 'uncategorized'  # Filter out uncategorized\n",
        "]).sort_values('total_cooccurrence', ascending=False)\n",
        "\n",
        "print(\"\\n🎯 Top semantic category co-occurrences:\")\n",
        "for _, row in category_cooccurrence_df.head(15).iterrows():\n",
        "    if row['category1'] != row['category2']:  # Different categories\n",
        "        print(f\"  {row['category1']} + {row['category2']}: {row['total_cooccurrence']} co-occurrences\")\n",
        "    else:  # Same category (internal consistency)\n",
        "        print(f\"  {row['category1']} (internal): {row['total_cooccurrence']} co-occurrences\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Enhanced Dataset Creation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive enhanced dataset\n",
        "print(\"💎 Creating enhanced dataset with all metadata...\")\n",
        "\n",
        "# Merge frequency statistics with root data\n",
        "frequency_lookup = frequency_stats.set_index('root').to_dict('index')\n",
        "\n",
        "def add_frequency_info(root):\n",
        "    if pd.isna(root) or root not in frequency_lookup:\n",
        "        return {'total_freq': 0, 'meccan_freq': 0, 'medinan_freq': 0, 'meccan_ratio': 0, 'frequency_rank': 0}\n",
        "    info = frequency_lookup[root]\n",
        "    return {\n",
        "        'total_freq': info['total_frequency'],\n",
        "        'meccan_freq': info['meccan_frequency'], \n",
        "        'medinan_freq': info['medinan_frequency'],\n",
        "        'meccan_ratio': info['meccan_ratio'],\n",
        "        'frequency_rank': frequency_stats[frequency_stats['root'] == root].index[0] + 1\n",
        "    }\n",
        "\n",
        "# Add all enhancements to the dataset\n",
        "enhanced_quran = quran_enhanced.copy()\n",
        "\n",
        "# Add frequency information\n",
        "freq_info = enhanced_quran['Root'].apply(add_frequency_info)\n",
        "for key in ['total_freq', 'meccan_freq', 'medinan_freq', 'meccan_ratio', 'frequency_rank']:\n",
        "    enhanced_quran[f'root_{key}'] = [info[key] for info in freq_info]\n",
        "\n",
        "# Add Arabic root form\n",
        "enhanced_quran['root_arabic'] = enhanced_quran['Root'].apply(lambda x: buck_to_arabic(x) if pd.notna(x) else '')\n",
        "\n",
        "# Add rarity classification\n",
        "def classify_rarity(freq):\n",
        "    if freq == 0: return 'no_root'\n",
        "    elif freq == 1: return 'hapax_legomena'\n",
        "    elif freq <= 5: return 'very_rare'\n",
        "    elif freq <= 20: return 'rare'\n",
        "    elif freq <= 100: return 'common'\n",
        "    else: return 'very_common'\n",
        "\n",
        "enhanced_quran['root_rarity'] = enhanced_quran['root_total_freq'].apply(classify_rarity)\n",
        "\n",
        "# Add revelation preference classification\n",
        "def classify_revelation_preference(ratio, total_freq):\n",
        "    if total_freq < 3: return 'insufficient_data'\n",
        "    elif ratio > 0.8: return 'strongly_meccan'\n",
        "    elif ratio > 0.6: return 'meccan_leaning'\n",
        "    elif ratio < 0.2: return 'strongly_medinan'\n",
        "    elif ratio < 0.4: return 'medinan_leaning'\n",
        "    else: return 'balanced'\n",
        "\n",
        "enhanced_quran['revelation_preference'] = enhanced_quran.apply(\n",
        "    lambda row: classify_revelation_preference(row['root_meccan_ratio'], row['root_total_freq']), axis=1\n",
        ")\n",
        "\n",
        "print(f\"✅ Enhanced dataset created with {len(enhanced_quran)} entries\")\n",
        "print(f\"New columns added: {[col for col in enhanced_quran.columns if col not in quran.columns]}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. Data Export and Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save enhanced datasets\n",
        "print(\"💾 Saving enhanced datasets...\")\n",
        "\n",
        "# Main enhanced dataset\n",
        "enhanced_quran.to_csv('quran-enhanced-phase1.csv', index=False)\n",
        "print(f\"✅ Saved main enhanced dataset: quran-enhanced-phase1.csv\")\n",
        "\n",
        "# Frequency statistics\n",
        "frequency_stats.to_csv('root-frequency-analysis.csv', index=False)\n",
        "print(f\"✅ Saved frequency analysis: root-frequency-analysis.csv\")\n",
        "\n",
        "# Semantic category analysis\n",
        "category_stats.to_csv('semantic-category-analysis.csv')\n",
        "print(f\"✅ Saved category analysis: semantic-category-analysis.csv\")\n",
        "\n",
        "# Co-occurrence matrices\n",
        "cooccurrence_df.to_csv('root-cooccurrence-matrix.csv', index=False)\n",
        "category_cooccurrence_df.to_csv('category-cooccurrence-matrix.csv', index=False)\n",
        "print(f\"✅ Saved co-occurrence matrices\")\n",
        "\n",
        "# Thematic distribution by sura\n",
        "sura_theme_distribution.to_csv('sura-thematic-distribution.csv')\n",
        "sura_theme_relative.to_csv('sura-thematic-relative.csv')\n",
        "print(f\"✅ Saved thematic distributions\")\n",
        "\n",
        "# Create metadata summary\n",
        "metadata_summary = {\n",
        "    'dataset_info': {\n",
        "        'total_entries': len(enhanced_quran),\n",
        "        'entries_with_roots': enhanced_quran['Root'].notna().sum(),\n",
        "        'unique_roots': enhanced_quran['Root'].nunique(),\n",
        "        'enhancement_date': pd.Timestamp.now().isoformat()\n",
        "    },\n",
        "    'semantic_categories': list(semantic_categories.keys()),\n",
        "    'frequency_statistics': {\n",
        "        'most_frequent_root': frequency_stats.iloc[0]['root'],\n",
        "        'most_frequent_count': int(frequency_stats.iloc[0]['total_frequency']),\n",
        "        'hapax_legomena_count': len(frequency_stats[frequency_stats['total_frequency'] == 1]),\n",
        "        'rare_roots_count': len(frequency_stats[frequency_stats['total_frequency'] <= 5])\n",
        "    },\n",
        "    'co_occurrence_stats': {\n",
        "        'unique_pairs': len(cooccurrence_df),\n",
        "        'total_co_occurrences': total_pairs,\n",
        "        'top_pair': (cooccurrence_df.iloc[0]['root1'], cooccurrence_df.iloc[0]['root2']),\n",
        "        'top_pair_count': int(cooccurrence_df.iloc[0]['cooccurrence_count'])\n",
        "    }\n",
        "}\n",
        "\n",
        "with open('enhancement-metadata.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(metadata_summary, f, indent=2, ensure_ascii=False)\n",
        "print(f\"✅ Saved metadata summary: enhancement-metadata.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final comprehensive summary\n",
        "print(\"📋 PHASE 1 ENHANCEMENT SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(f\"\\n📊 Dataset Enhancements:\")\n",
        "print(f\"  Original entries: {len(quran):,}\")\n",
        "print(f\"  Enhanced entries: {len(enhanced_quran):,}\")\n",
        "print(f\"  New metadata columns: {len(enhanced_quran.columns) - len(quran.columns)}\")\n",
        "\n",
        "print(f\"\\n🎯 Semantic Analysis:\")\n",
        "print(f\"  Categories defined: {len(semantic_categories)}\")\n",
        "print(f\"  Roots categorized: {sum(len(roots) for roots in semantic_categories.values())}\")\n",
        "print(f\"  Category coverage: {(enhanced_quran['semantic_category'] != 'uncategorized').sum() / len(enhanced_quran) * 100:.1f}%\")\n",
        "\n",
        "print(f\"\\n📈 Frequency Analysis:\")\n",
        "print(f\"  Unique roots analyzed: {len(frequency_stats)}\")\n",
        "print(f\"  Hapax legomena: {len(frequency_stats[frequency_stats['total_frequency'] == 1])}\")\n",
        "print(f\"  Strongly Meccan roots: {len(meccan_preferred)}\")\n",
        "print(f\"  Strongly Medinan roots: {len(medinan_preferred)}\")\n",
        "\n",
        "print(f\"\\n🔗 Co-occurrence Analysis:\")\n",
        "print(f\"  Verses analyzed: {len(verse_roots)}\")\n",
        "print(f\"  Root pairs found: {len(cooccurrence_df)}\")\n",
        "print(f\"  Category pairs: {len(category_cooccurrence_df)}\")\n",
        "\n",
        "print(f\"\\n💾 Files Created:\")\n",
        "files_created = [\n",
        "    'quran-enhanced-phase1.csv',\n",
        "    'root-frequency-analysis.csv', \n",
        "    'semantic-category-analysis.csv',\n",
        "    'root-cooccurrence-matrix.csv',\n",
        "    'category-cooccurrence-matrix.csv',\n",
        "    'sura-thematic-distribution.csv',\n",
        "    'sura-thematic-relative.csv',\n",
        "    'enhancement-metadata.json'\n",
        "]\n",
        "for file in files_created:\n",
        "    print(f\"  ✅ {file}\")\n",
        "\n",
        "print(f\"\\n🚀 Ready for Phase 2: Backend API Development\")\n",
        "print(f\"\\n✨ Phase 1 Enhancement Complete! ✨\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
